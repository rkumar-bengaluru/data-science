{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdfa1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfb8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters (& \\n) from category/sub category/type\n",
    "def splitcategory(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    else:\n",
    "        if isinstance(x, str):\n",
    "            res = re.split('& |, |\\*|\\n', x)\n",
    "            return res\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "# function to change characters to lower case\n",
    "def cleaner(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "# change text to lower case\n",
    "def changeCase(x):\n",
    "    return str.lower(x)\n",
    "\n",
    "# merge all text columns\n",
    "def couple(x):\n",
    "    return x['zzibrnd'] + ' ' + ' '.join(x['TherapeuticClass_new']) + ' '.join( x['PrincipalName_new']) + ' ' + x['Description'] \n",
    "\n",
    "def preprocess_text(question):\n",
    "    question = question.replace(\"S08_\", \"\")\n",
    "    question = question.replace(\"NOTTTT  FOUND\", \"\")\n",
    "    question = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", question) # remove text between brackets\n",
    "    question = re.sub(\"[^\\w\\s]\", \"\", question) # remove punctuations\n",
    "    re.sub(\"\\s+\", \" \", question) # remove multiple white spaces\n",
    "    re.sub(\"[\\t\\n]\", \"\", question) # remove tabs and newline characters\n",
    "    re.sub(\"[_]\", \"\", question) # remove tabs and newline characters\n",
    "    question = question.lower().strip()\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92db5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/16-Projects/zuel/data/2001_all_materials.csv')\n",
    "df['zzibrnd'] = df['zzibrnd'].astype(str)\n",
    "df['TherapeuticClass'] = df['TherapeuticClass'].astype(str)\n",
    "df['PrincipalName'] = df['PrincipalName'].astype(str)\n",
    "df['Description'] = df['Description'].astype(str)\n",
    "# remove special characters\n",
    "df['zzibrnd_new'] = df['zzibrnd'].apply(splitcategory)\n",
    "df['TherapeuticClass_new'] = df['TherapeuticClass'].apply(splitcategory)\n",
    "df['PrincipalName_new'] = df['PrincipalName'].apply(splitcategory)\n",
    "\n",
    "\n",
    "# mix all text columns\n",
    "df['soup'] = df.apply(couple, axis=1)\n",
    "df['soup'] = df['soup'].apply(changeCase)\n",
    "df['soup'] = df['soup'].apply(preprocess_text)\n",
    "text = df['soup']\n",
    "\n",
    "vocab = sorted(set(\"\".join(text)))\n",
    "sos_token = '['\n",
    "eos_token = ']'\n",
    "BATCH_FIRST=True\n",
    "BATCH_SIZE=2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0cafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "    def __init__(self, questions, vocab, sos_token, eos_token, batch_first=False):\n",
    "        \n",
    "        # initialize parameters\n",
    "        self.sos_idx = 0\n",
    "        self.eos_idx = 1\n",
    "        self.int2char = {self.sos_idx: sos_token, self.eos_idx: eos_token} # insert start of sentence and end of sentence tokens\n",
    "        self.int2char.update({idx: char for idx, char in enumerate(vocab, start=self.eos_idx+1)})\n",
    "        self.char2int = {char: idx for idx, char in self.int2char.items()}\n",
    "        self.n_chars = len(self.int2char)\n",
    "        \n",
    "        # encode and pad questions\n",
    "        self.questions_encoded = pad_sequence([self.encode_question(q) for q in questions], \\\n",
    "                                              batch_first=batch_first)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.questions_encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.questions_encoded[idx]\n",
    "        \n",
    "    def encode_question(self, question):\n",
    "        '''\n",
    "        encode question as char indices and perform one-hot encoding\n",
    "        '''\n",
    "        question_encoded = [self.sos_idx] # append sos\n",
    "        for char in question:\n",
    "            question_encoded.append(self.char2int[char])\n",
    "        question_encoded.append(self.eos_idx) # append eos\n",
    "        return F.one_hot(torch.tensor(question_encoded, dtype=torch.long), self.n_chars).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a9dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class charRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, VOCAB_SIZE, HIDDEN_SIZE, N_LAYERS=2, P_DROPOUT=0.5, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.HIDDEN_SIZE = HIDDEN_SIZE\n",
    "        self.N_LAYERS = N_LAYERS\n",
    "        self.lstm = nn.LSTM(VOCAB_SIZE, HIDDEN_SIZE, batch_first=batch_first, \n",
    "                            dropout=P_DROPOUT, num_layers=N_LAYERS)\n",
    "        self.dropout = nn.Dropout(P_DROPOUT)\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, VOCAB_SIZE)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        lstm_out, hidden = self.lstm(inputs, hidden)\n",
    "        \n",
    "        # flatten the lstm output\n",
    "        lstm_out = torch.flatten(lstm_out, start_dim=0, end_dim=1)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, BATCH_SIZE, device):\n",
    "        hidden = (torch.zeros((self.N_LAYERS, BATCH_SIZE, self.HIDDEN_SIZE), dtype=torch.float32).to(device),\n",
    "                  torch.zeros((self.N_LAYERS, BATCH_SIZE, self.HIDDEN_SIZE), dtype=torch.float32).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b2cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(\"\".join(text)))\n",
    "sos_token = '['\n",
    "eos_token = ']'\n",
    "BATCH_FIRST=True\n",
    "BATCH_SIZE=2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a7e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train =text[:]\n",
    "train_dataset = QuestionsDataset(questions_train, vocab, sos_token, eos_token, batch_first=BATCH_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2845c49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charRNN(\n",
       "  (lstm): LSTM(44, 512, num_layers=3, batch_first=True, dropout=0.4)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE=train_dataset.n_chars\n",
    "HIDDEN_SIZE=512\n",
    "N_LAYERS=3\n",
    "P_DROPOUT = 0.4\n",
    "model = charRNN(VOCAB_SIZE, HIDDEN_SIZE, N_LAYERS, P_DROPOUT, BATCH_FIRST)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa9598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charRNN(\n",
       "  (lstm): LSTM(44, 512, num_layers=3, batch_first=True, dropout=0.4)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('charRNN_questions_epoch_100.pt',map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2dfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText:\n",
    "    def __init__(self, model, k, int2char, char2int, device):\n",
    "        self.int2char = int2char\n",
    "        self.char2int = char2int\n",
    "        self.n_chars = len(int2char)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.sos_token = self.int2char[0]\n",
    "        self.eos_token = self.int2char[1]\n",
    "        \n",
    "    def predict_next_char(self, hidden, input_char):\n",
    "        \n",
    "        # encode char\n",
    "        char_one_hot = self.encode_char(input_char)\n",
    "\n",
    "        # get the predictions\n",
    "        with torch.no_grad():\n",
    "            out, hidden = self.model(char_one_hot, hidden)\n",
    "            \n",
    "            # convert the output to a character probability distribution\n",
    "            p = F.softmax(out, dim=1)\n",
    "\n",
    "            # move to cpu as numpy doesn't support gpu\n",
    "            p = p.cpu()\n",
    "\n",
    "            # get top k characters from the distribution\n",
    "            values, indices = p.topk(self.k)\n",
    "\n",
    "        indices = indices.squeeze().numpy()\n",
    "        values = values.squeeze().numpy()\n",
    "\n",
    "        # sample any char from the top k chars using the output softmax distribution\n",
    "        char_pred = np.random.choice(indices, size=1, p=values/values.sum())\n",
    "\n",
    "        return self.int2char[char_pred[0]], hidden\n",
    "    \n",
    "    def generate_text(self, prime, max_chars=20):\n",
    "        \n",
    "        prime = self.sos_token + prime\n",
    "\n",
    "        all_chars = [char for char in prime]\n",
    "        print(all_chars)\n",
    "        hidden = model.init_hidden(1, self.device)\n",
    "\n",
    "        # build up the hidden state using the initial prime\n",
    "        for char in prime:\n",
    "            char_pred, hidden = self.predict_next_char(hidden, char)\n",
    "\n",
    "        all_chars.append(char_pred)\n",
    "        print(all_chars)\n",
    "\n",
    "        # generate n chars\n",
    "        c = len(all_chars)\n",
    "        print(c)\n",
    "        while char_pred != self.eos_token:\n",
    "            if c == max_chars:\n",
    "                break\n",
    "            char_pred, hidden = self.predict_next_char(hidden, all_chars[-1])\n",
    "            all_chars.append(char_pred)\n",
    "            c += 1\n",
    "\n",
    "        return \"\".join(all_chars)\n",
    "        \n",
    "    def encode_char(self, char):\n",
    "        char_int = self.char2int[char]\n",
    "        char_one_hot = F.one_hot(torch.tensor(char_int), self.n_chars).float()\n",
    "        return char_one_hot.unsqueeze(0).unsqueeze(0).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1606e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 's', 'o']\n",
      "['[', 's', 'o', 'l']\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[solaray chromiacin t other mineral supplementsgroway sdn bhd  solaray par iliancitacsplus  20s2tabs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "text_generator = GenerateText(model, k, train_dataset.int2char, train_dataset.char2int, device)\n",
    "response = text_generator.generate_text('so', max_chars=100)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b84c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
