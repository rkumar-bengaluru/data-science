{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Convolution and transformations\n",
    "### LECTURE: Creating and using custom DataSets\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fD1Q1CK35Pv"
   },
   "outputs": [],
   "source": [
    "# FYI, review paper on data augmentation in DL:\n",
    "# https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10756\\1514840182.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import transformations and dataset/loader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VhIKo0_iaGz2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_data/mnist_train_small.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import dataset (comes with colab!)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_data/mnist_train_small.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# extract only the first 8\u001b[39;00m\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/mnist_train_small.csv'"
     ]
    }
   ],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract only the first 8\n",
    "labels = data[:8,0]\n",
    "data   = data[:8,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# reshape to 2D!\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n",
    "\n",
    "# check sizes\n",
    "print(dataNorm.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# convert to torch tensor format\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-vy8Pbj4Rg1"
   },
   "source": [
    "# Create a new class to create our custom dataset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VcIE1DExDvV"
   },
   "outputs": [],
   "source": [
    "# My custom dataset class is modeled after the official class\n",
    "??torch.utils.data.TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDl-yEbpvg2I"
   },
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "  def __init__(self, tensors, transform=None):\n",
    "\n",
    "    # check that sizes of data and labels match\n",
    "    assert all(tensors[0].size(0)==t.size(0) for t in tensors), \"Size mismatch between tensors\"\n",
    "    \n",
    "    # assign inputs\n",
    "    self.tensors   = tensors\n",
    "    self.transform = transform\n",
    "\n",
    "  # what to do when someone wants and item from the dataset\n",
    "  def __getitem__(self, index): \n",
    "\n",
    "    # return transformed version of x if there are transforms\n",
    "    if self.transform:\n",
    "      x = self.transform(self.tensors[0][index])\n",
    "    else:\n",
    "      x = self.tensors[0][index]\n",
    "\n",
    "    # and return label\n",
    "    y = self.tensors[1][index]\n",
    "\n",
    "    return x,y # return the (data,label) tuple\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq1WEKwl4ew9"
   },
   "source": [
    "# data -> dataset -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NP5mv3Khr0Eh"
   },
   "outputs": [],
   "source": [
    "# Note: several transforms work only on PIL-format data, so it's common to transform\n",
    "#       to PIL, apply transformations, then transform back to tensor.\n",
    "\n",
    "# create a list of transforms to apply to the image\n",
    "imgtrans = T.Compose([ \n",
    "                      T.ToPILImage(),\n",
    "                      T.RandomVerticalFlip(p=.5),\n",
    "                      # T.RandomRotation(90), \n",
    "                      T.ToTensor()\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlYbyhTgxMt3"
   },
   "outputs": [],
   "source": [
    "# now convert the data into datasets and then dataloaders\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "# NOTE: we have no test data here, but you should apply the same transformations to the test data\n",
    "train_data = customDataset((dataT,labelsT),imgtrans)\n",
    "\n",
    "# translate into dataloader objects\n",
    "dataLoaded = DataLoader(train_data,batch_size=8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHAqShzs9-or"
   },
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u__Nn2BG4u3d"
   },
   "source": [
    "# Let's see the effects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AjYQPw2wuNl"
   },
   "outputs": [],
   "source": [
    "# import data from the dataloader, just like during training\n",
    "X,y = next(iter(dataLoaded))\n",
    "\n",
    "\n",
    "# create a figure\n",
    "fig,axs = plt.subplots(2,8,figsize=(16,4))\n",
    "\n",
    "\n",
    "# loop over images in the dataset\n",
    "for i in range(8):\n",
    "\n",
    "  # draw images\n",
    "  axs[0,i].imshow(dataT[i,0,:,:].detach(),cmap='gray')\n",
    "  axs[1,i].imshow(X[i,0,:,:].detach(),cmap='gray')\n",
    "\n",
    "  # some niceties\n",
    "  for row in range(2):\n",
    "    axs[row,i].set_xticks([])\n",
    "    axs[row,i].set_yticks([])\n",
    "\n",
    "# row labels\n",
    "axs[0,0].set_ylabel('Original')\n",
    "axs[1,0].set_ylabel('torch dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwBwIb1yynNB"
   },
   "outputs": [],
   "source": [
    "# Important to know: we haven't actually increased the amount of data\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dimcax6w0vvY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPbD7UUlxPnb4BI+hE9YoGH",
   "collapsed_sections": [],
   "name": "DUDL_convolution_customDataSet.ipynb",
   "provenance": [
    {
     "file_id": "1GRajDS-VF5z8IslzZuMqbis3X6HDD-Uo",
     "timestamp": 1619968661706
    },
    {
     "file_id": "1m0n2-UmB2tJiIDadlFkE6L5A4iZSqeBf",
     "timestamp": 1619459134813
    },
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619444797767
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
