{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Overfitting, cross-validation, regularization\n",
    "### LECTURE: Cross-validation -- manual separation\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\sofware\\anaconda3\\envs\\projects\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset (comes with seaborn)\n",
    "import seaborn as sns\n",
    "#iris = sns.load_dataset('../../data/iris.csv')\n",
    "iris = pd.read_csv('../../data/iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa'] = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiAFAHB20DQc"
   },
   "source": [
    "# Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mwhgV43SXbCN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False,  True, False,  True,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "        True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (no devset here)\n",
    "\n",
    "# how many training examples\n",
    "propTraining = .8 # in proportion, not percent\n",
    "nTraining = int(len(labels)*propTraining)\n",
    "\n",
    "# initialize a boolean vector to select data and labels\n",
    "traintestBool = np.zeros(len(labels),dtype=bool)\n",
    "\n",
    "# is this the correct way to select samples?\n",
    "# traintestBool[range(nTraining)] = True\n",
    "\n",
    "# this is better, but why?\n",
    "items2use4train = np.random.choice(range(len(labels)),nTraining,replace=False)\n",
    "traintestBool[items2use4train] = True\n",
    "\n",
    "traintestBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LPcj_f92bYs0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full data:\n",
      "tensor(1.)\n",
      " \n",
      "Average of training data:\n",
      "tensor(1.0417)\n",
      " \n",
      "Average of test data:\n",
      "tensor(0.8333)\n"
     ]
    }
   ],
   "source": [
    "# test whether it's balanced\n",
    "print('Average of full data:')\n",
    "print( torch.mean(labels.float()) ) # =1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data:')\n",
    "print( torch.mean(labels[traintestBool].float()) ) # should be 1...\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data:')\n",
    "print( torch.mean(labels[~traintestBool].float()) ) # should also be 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v0JMIGb1iV_9"
   },
   "outputs": [],
   "source": [
    "# create the ANN model\n",
    "\n",
    "# model architecture\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4,64),   # input layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,64),  # hidden layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,3),   # output units\n",
    "      )\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iyxr6_P9b-x5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([120, 4])\n",
      "torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# entire dataset\n",
    "print( data.shape )\n",
    "\n",
    "# training set\n",
    "print( data[traintestBool,:].shape )\n",
    "\n",
    "# test set\n",
    "print( data[~traintestBool,:].shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbx3Zkc_0UT8"
   },
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "numepochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNiris(data[traintestBool,:])\n",
    "\n",
    "  # compute accuracy (note: denser than previous code!)\n",
    "  ongoingAcc.append( 100*torch.mean(\n",
    "              (torch.argmax(yHat,axis=1) == labels[traintestBool]).float()) )\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels[traintestBool])\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vXku7xIdcu7Y"
   },
   "outputs": [],
   "source": [
    "# compute train and test accuracies\n",
    "\n",
    "# final forward pass USING TRAINING DATA\n",
    "predictions = ANNiris(data[traintestBool,:])\n",
    "trainacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[traintestBool]).float())\n",
    "\n",
    "\n",
    "# final forward pass USING TEST DATA!\n",
    "predictions = ANNiris(data[~traintestBool,:])\n",
    "testacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[~traintestBool]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TRAIN accuracy: 98.3333%\n",
      "Final TEST accuracy:  100%\n"
     ]
    }
   ],
   "source": [
    "# report accuracies\n",
    "\n",
    "print('Final TRAIN accuracy: %g%%' %trainacc)\n",
    "print('Final TEST accuracy:  %g%%' %testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kcbD9nZmd9nu"
   },
   "outputs": [],
   "source": [
    "# normally also inspect losses and accuracy by epoch, etc etc etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAzQqbq8fqSt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwTbABK7fqzZ"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jWC_SDDCfrAo"
   },
   "outputs": [],
   "source": [
    "# 1) Randomly assigning data samples to be in the train vs test phase produced a statistical balance, but it was \n",
    "#    not perfect. Write an algorithm that will guarantee a balance of flower types while also randomly assigning\n",
    "#    samples to be in train vs. test.\n",
    "# \n",
    "# 2) Revert the code to its original form -- with the strong imbalance in flower types. Then train the model. What are\n",
    "#    the train and test accuracies? Compute the accuracy separately for each type of flower to see whether the model\n",
    "#    learned some categories, or whether it performed equally on all three categories. Are you surprised at the results? \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNk9aAiPToKpfieCvxrzbDR",
   "collapsed_sections": [],
   "name": "DUDL_overfitting_manual.ipynb",
   "provenance": [
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
