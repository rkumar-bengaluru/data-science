{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac2d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec8954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce40526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a1f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(d,k,v):\n",
    "    if k not in d:\n",
    "        d[k] = []\n",
    "    d[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "467754d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlinesfromtextfile(filename):\n",
    "    lines = []\n",
    "    for line in open(filename):\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31eb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_second_order(lines):\n",
    "    initial = {} # dictionary of pharases\n",
    "    first_order_markov = {} # second word only.\n",
    "    second_order_markov = {} # from second word onwards\n",
    "    for line in lines:\n",
    "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "        T = len(tokens)\n",
    "        for i in range(T):\n",
    "            t = tokens[i]\n",
    "            if i ==0:\n",
    "                # first word\n",
    "                initial[t] = initial.get(t,0.) + 1\n",
    "            else:\n",
    "                t_1 = tokens[i -1]\n",
    "                if i == T-1:\n",
    "                    # last word\n",
    "                    add2dict(second_order_markov, (t_1,t),'END')\n",
    "                if i == 1:\n",
    "                    # second word\n",
    "                    add2dict(first_order_markov,t_1,t)\n",
    "                else:\n",
    "                    # all the remaining.\n",
    "                    t_2 = tokens[i-2]\n",
    "                    add2dict(second_order_markov, (t_2,t_1),t)\n",
    "    return initial,first_order_markov,second_order_markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f17a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize distribution\n",
    "def normalize_initial_distribution(initial):\n",
    "    initial_total = sum(initial.values())\n",
    "    for t,c in initial.items():\n",
    "        initial[t] = c/initial_total\n",
    "\n",
    "def normalize_markov_order_distribution(ts):\n",
    "    d = {}\n",
    "    n = len(ts)\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t,0.) + 1\n",
    "    for t,c in d.items():\n",
    "        d[t] = c/n\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a542ef21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two roads diverged in a yellow wood,\\n',\n",
       " 'And sorry I could not travel both\\n',\n",
       " 'And be one traveler, long I stood\\n',\n",
       " 'And looked down one as far as I could\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with 2 lines\n",
    "test_data = getlinesfromtextfile('robert_frost.txt')[:4]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327c5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial\n",
      " {'two': 1.0, 'and': 3.0}\n",
      "first_order_markov\n",
      " {'two': ['roads'], 'and': ['sorry', 'be', 'looked']}\n",
      "second_order_markov\n",
      " {('two', 'roads'): ['diverged'], ('roads', 'diverged'): ['in'], ('diverged', 'in'): ['a'], ('in', 'a'): ['yellow'], ('yellow', 'wood'): ['END'], ('a', 'yellow'): ['wood'], ('and', 'sorry'): ['i'], ('sorry', 'i'): ['could'], ('i', 'could'): ['not', 'END'], ('could', 'not'): ['travel'], ('travel', 'both'): ['END'], ('not', 'travel'): ['both'], ('and', 'be'): ['one'], ('be', 'one'): ['traveler'], ('one', 'traveler'): ['long'], ('traveler', 'long'): ['i'], ('i', 'stood'): ['END'], ('long', 'i'): ['stood'], ('and', 'looked'): ['down'], ('looked', 'down'): ['one'], ('down', 'one'): ['as'], ('one', 'as'): ['far'], ('as', 'far'): ['as'], ('far', 'as'): ['i'], ('as', 'i'): ['could']}\n"
     ]
    }
   ],
   "source": [
    "initial,first_order_markov,second_order_markov = markov_second_order(test_data)\n",
    "print('initial\\n',initial)\n",
    "print('first_order_markov\\n',first_order_markov)\n",
    "print('second_order_markov\\n',second_order_markov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60faca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\n",
      " ['Two roads diverged in a yellow wood,\\n', 'And sorry I could not travel both\\n', 'And be one traveler, long I stood\\n', 'And looked down one as far as I could\\n']\n",
      "initial\n",
      " {'two': 0.25, 'and': 0.75}\n",
      "first_order_markov\n",
      " {'two': {'roads': 1.0}, 'and': {'sorry': 0.3333333333333333, 'be': 0.3333333333333333, 'looked': 0.3333333333333333}}\n",
      "second_order_markov\n",
      " {('two', 'roads'): {'diverged': 1.0}, ('roads', 'diverged'): {'in': 1.0}, ('diverged', 'in'): {'a': 1.0}, ('in', 'a'): {'yellow': 1.0}, ('yellow', 'wood'): {'END': 1.0}, ('a', 'yellow'): {'wood': 1.0}, ('and', 'sorry'): {'i': 1.0}, ('sorry', 'i'): {'could': 1.0}, ('i', 'could'): {'not': 0.5, 'END': 0.5}, ('could', 'not'): {'travel': 1.0}, ('travel', 'both'): {'END': 1.0}, ('not', 'travel'): {'both': 1.0}, ('and', 'be'): {'one': 1.0}, ('be', 'one'): {'traveler': 1.0}, ('one', 'traveler'): {'long': 1.0}, ('traveler', 'long'): {'i': 1.0}, ('i', 'stood'): {'END': 1.0}, ('long', 'i'): {'stood': 1.0}, ('and', 'looked'): {'down': 1.0}, ('looked', 'down'): {'one': 1.0}, ('down', 'one'): {'as': 1.0}, ('one', 'as'): {'far': 1.0}, ('as', 'far'): {'as': 1.0}, ('far', 'as'): {'i': 1.0}, ('as', 'i'): {'could': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "def normalize(initial,first_order,second_order):\n",
    "    normalize_initial_distribution(initial)\n",
    "    for t_1,ts in first_order.items():\n",
    "        first_order[t_1] = normalize_markov_order_distribution(ts)\n",
    "    for t_1,ts in second_order.items():\n",
    "        second_order[t_1] = normalize_markov_order_distribution(ts)\n",
    "\n",
    "normalize(initial,first_order_markov,second_order_markov)\n",
    "print('test_data\\n',test_data)\n",
    "print('initial\\n',initial)\n",
    "print('first_order_markov\\n',first_order_markov)\n",
    "print('second_order_markov\\n',second_order_markov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d829fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for t,p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d3e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    for i in range(2):\n",
    "        sentence = []\n",
    "        \n",
    "        # start word\n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "        \n",
    "        # sample second word\n",
    "        w1 = sample_word(first_order_markov[w0])\n",
    "        sentence.append(w1)\n",
    "        \n",
    "        # generate second order till end\n",
    "        while True:\n",
    "            w2 = sample_word(second_order_markov[w0,w1])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5f144c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two roads diverged in a yellow wood\n",
      "and looked down one as far as i could not travel both\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8428b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
