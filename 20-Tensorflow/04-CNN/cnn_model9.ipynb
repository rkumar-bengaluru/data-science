{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c0efba",
   "metadata": {},
   "source": [
    "# Multiclass Image Classification\n",
    "\n",
    "* Create Data with 10 Image Classification\n",
    "* Visualize Data\n",
    "* Preprocess the Data\n",
    "* Create the Model\n",
    "* Fit the Model\n",
    "* Evaluate the Model\n",
    "* Adjust Hyperparams to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5f6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = ['samosa','pizza','bread_pudding','caesar_salad',\n",
    "               'chicken_curry','chicken_wings','donuts','fried_rice','ice_cream','waffles']\n",
    "len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7b4a4",
   "metadata": {},
   "source": [
    "## Create Data with 10 Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e39e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PrepareData:\n",
    "    \n",
    "    def __init__(self, classnames):\n",
    "        self.classnames = classnames\n",
    "        self.IMAGES_DIR    = 'images'\n",
    "        self.TRAIN_DIR     = 'train'\n",
    "        self.TEST_DIR      = 'test'\n",
    "        self.META_DIR      = 'meta'\n",
    "        self.DIR_SEPARATOR = '/'\n",
    "        self.IMAGE_TYPE    = '.jpg'\n",
    "        \n",
    "    def create_10_food_classes(self,src_root,destination_root):\n",
    "        '''\n",
    "        create all required directories\n",
    "        '''\n",
    "        self.create_required_dir()\n",
    "        keys = json.load(open(src_root + self.DIR_SEPARATOR + self.META_DIR + self.DIR_SEPARATOR + self.TRAIN_DIR + '.json'))\n",
    "        # copy train data\n",
    "        for label in tqdm(self.classnames):\n",
    "            images_for_label = keys[label]\n",
    "            print(f'no of images for label {label} is {len(images_for_label)}')\n",
    "            for img in images_for_label:\n",
    "                src_path = src_root + self.DIR_SEPARATOR + self.IMAGES_DIR + self.DIR_SEPARATOR + img + self.IMAGE_TYPE\n",
    "                destination_path = destination_root + self.DIR_SEPARATOR + self.TRAIN_DIR + self.DIR_SEPARATOR + img + self.IMAGE_TYPE\n",
    "                if os.path.exists(destination_path) == False:\n",
    "                    shutil.copy(src_path,destination_path)\n",
    "        # copy test data\n",
    "        keys = json.load(open(src_root + self.DIR_SEPARATOR + self.META_DIR + self.DIR_SEPARATOR + self.TEST_DIR + '.json'))\n",
    "        for label in tqdm(self.classnames):\n",
    "            images_for_label = keys[label]\n",
    "            print(f'no of images for label {label} is {len(images_for_label)}')\n",
    "            for img in images_for_label:\n",
    "                src_path = src_root + self.DIR_SEPARATOR + self.IMAGES_DIR + self.DIR_SEPARATOR + img + self.IMAGE_TYPE\n",
    "                destination_path = destination_root + self.DIR_SEPARATOR + self.TEST_DIR + self.DIR_SEPARATOR + img + self.IMAGE_TYPE\n",
    "                if os.path.exists(destination_path) == False:\n",
    "                    shutil.copy(src_path,destination_path)\n",
    "\n",
    "    def create_required_dir(self):\n",
    "        '''\n",
    "        checks if the all requirements are met...\n",
    "        '''\n",
    "        print('checking if required directories are present...')\n",
    "        train_dir = '10-food-classes/train/'\n",
    "        test_dir  = '10-food-classes/test/'\n",
    "        for product in self.classnames:\n",
    "            train_path = train_dir + '/' + product + '/'\n",
    "            test_path  = test_dir + '/' + product + '/'\n",
    "            train_exists = os.path.exists(train_path)\n",
    "            test_exists  = os.path.exists(test_path)\n",
    "            if train_exists == False:\n",
    "                os.makedirs(train_path)\n",
    "                print(f'creating train directory {os.path.exists(train_path)}')\n",
    "            if test_exists == False:\n",
    "                os.makedirs(test_path)\n",
    "                print(f'creating test directory {os.path.exists(test_path)}')\n",
    "        print('all seems good...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c923004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking if required directories are present...\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "creating train directory True\n",
      "creating test directory True\n",
      "all seems good...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'food-101/meta/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m SRC_ROOT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood-101\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m DESTINATION_ROOT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-food-classes\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_10_food_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSRC_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDESTINATION_ROOT\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m, in \u001b[0;36mPrepareData.create_10_food_classes\u001b[0;34m(self, src_root, destination_root)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mcreate all required directories\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_required_dir()\n\u001b[0;32m---> 22\u001b[0m keys \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDIR_SEPARATOR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMETA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDIR_SEPARATOR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# copy train data\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassnames):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'food-101/meta/train.json'"
     ]
    }
   ],
   "source": [
    "p = PrepareData(CLASS_NAMES)\n",
    "SRC_ROOT = 'food-101'\n",
    "DESTINATION_ROOT = '10-food-classes'\n",
    "p.create_10_food_classes(SRC_ROOT,DESTINATION_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633d20b",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_10_class_images(classes,train_root):\n",
    "    rows = 2\n",
    "    cols = 5\n",
    "    i    = 0\n",
    "    sep  = '/'\n",
    "    train = 'train'\n",
    "    size  = (224,224)\n",
    "    \n",
    "    fig,axes = plt.subplots(rows,cols,figsize=(10,7))\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            label = classes[i]\n",
    "            random_img = random.choice(os.listdir(train_root + sep + train + sep + label + sep))\n",
    "            img = Image.open(train_root + sep + train + sep + label + sep + random_img)\n",
    "            img = img.resize(size)\n",
    "            #img = plt.imread(train_root + sep + train + sep + label + sep + random_img)\n",
    "            axes[row][col].imshow(img)\n",
    "            axes[row][col].set_title(label)\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f363cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '10-food-classes/'\n",
    "show_10_class_images(CLASS_NAMES,ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b6537",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade83373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class MulticlassClassification:\n",
    "    def __init__(self,root_dir):\n",
    "        print(f'creating multiclass classification model')\n",
    "        self.ROOT_DIR = root_dir\n",
    "        self.NAME = 'MulticlassClassification'\n",
    "        self.DIR_SEP = '/'\n",
    "        self.TRAIN_DIR = self.ROOT_DIR + self.DIR_SEP + 'train/'\n",
    "        self.TEST_DIR = self.ROOT_DIR + self.DIR_SEP + 'test/'\n",
    "        self.RESCALE  = 1./255\n",
    "        self.DATA_AUGMENT  = 0.2\n",
    "        self.IMG_WIDTH = 64\n",
    "        self.IMG_SIZE = (self.IMG_WIDTH,self.IMG_WIDTH)\n",
    "        self.MODE     = 'categorical'\n",
    "        self.FILTER_SIZE = 10\n",
    "        self.KERNEL_SIZE = (3,3)\n",
    "        self.RELU = 'relu'\n",
    "        self.SOFTMAX = 'softmax'\n",
    "        self.ISHAPE = (self.IMG_WIDTH,self.IMG_WIDTH,3)\n",
    "        self.EPOCHS = 5\n",
    "    \n",
    "    def build_data(self):\n",
    "        self.train_data_gen = ImageDataGenerator(rescale=self.RESCALE,\n",
    "                                                rotation_range=self.DATA_AUGMENT,\n",
    "                                                shear_range=self.DATA_AUGMENT,\n",
    "                                                zoom_range=self.DATA_AUGMENT,\n",
    "                                                width_shift_range=self.DATA_AUGMENT,\n",
    "                                                height_shift_range=self.DATA_AUGMENT,\n",
    "                                                horizontal_flip=True)\n",
    "        self.test_data_gen  = ImageDataGenerator(rescale=self.RESCALE)\n",
    "        self.train_data     = self.train_data_gen.flow_from_directory(directory=self.TRAIN_DIR,\n",
    "                                                                     target_size=self.IMG_SIZE,\n",
    "                                                                     class_mode= self.MODE)\n",
    "        self.test_data      = self.test_data_gen.flow_from_directory(directory=self.TEST_DIR,\n",
    "                                                                    target_size=self.IMG_SIZE,\n",
    "                                                                    class_mode=self.MODE)\n",
    "    \n",
    "    def create_model(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=self.FILTER_SIZE,\n",
    "                  kernel_size=self.KERNEL_SIZE,\n",
    "                  activation=self.RELU,\n",
    "                  input_shape=self.ISHAPE),\n",
    "            Conv2D(filters=self.FILTER_SIZE,kernel_size=self.KERNEL_SIZE,activation=self.RELU),\n",
    "            MaxPool2D(),\n",
    "            Conv2D(filters=self.FILTER_SIZE,kernel_size=self.KERNEL_SIZE,activation=self.RELU),\n",
    "            Conv2D(filters=self.FILTER_SIZE,kernel_size=self.KERNEL_SIZE,activation=self.RELU),\n",
    "            MaxPool2D(),\n",
    "            Flatten(),\n",
    "            Dense(10,activation=self.SOFTMAX)\n",
    "            \n",
    "        ],name=self.NAME)\n",
    "        # compile the model\n",
    "        self.model.compile(loss=CategoricalCrossentropy(),\n",
    "                          optimizer=Adam(),\n",
    "                          metrics=['accuracy'])\n",
    "        # print the summary\n",
    "        self.model.summary()\n",
    "        return self.model\n",
    "    \n",
    "    def fit_model(self):\n",
    "        self.history = self.model.fit(self.train_data,\n",
    "                                     epochs=self.EPOCHS,\n",
    "                                     steps_per_epoch=len(self.train_data),\n",
    "                                     validation_data=self.test_data,\n",
    "                                     validation_steps=len(self.test_data))\n",
    "        return self.history\n",
    "    \n",
    "    def evaluate(self):\n",
    "       return self.model.evaluate(self.test_data)\n",
    "\n",
    "    def get_test_data(self):\n",
    "        return self.test_data\n",
    "    \n",
    "    def plot_loss_and_accuracy_curves(self,history):\n",
    "        fig,ax = plt.subplots(1,2,figsize=(10, 7))\n",
    "        i = 0\n",
    "        ax[i].plot(history.history['loss'])\n",
    "        ax[i].plot(history.history['val_loss'])\n",
    "        ax[i].set_title('training v/s validation loss')\n",
    "        ax[i].set(xlabel='epochs', ylabel='loss')\n",
    "        ax[i].legend(['train data','test data'])\n",
    "        i = 1\n",
    "        ax[i].plot(history.history['accuracy'])\n",
    "        ax[i].plot(history.history['val_accuracy'])\n",
    "        ax[i].set_title('training v/s validation accuracy')\n",
    "        ax[i].set(xlabel='epochs', ylabel='accuracy')\n",
    "        ax[i].legend(['train data','test data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '10-food-classes/'\n",
    "classification = MulticlassClassification(root_dir=ROOT_DIR)\n",
    "classification.build_data()\n",
    "model = classification.create_model()\n",
    "history = classification.fit_model()\n",
    "classification.plot_loss_and_accuracy_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703aedc",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b73b3",
   "metadata": {},
   "source": [
    "## Make Prediction on custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_image(filename,image_shape=64):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_image(img)\n",
    "    img = tf.image.resize(img,size=[image_shape,image_shape])\n",
    "    img = img/255.\n",
    "    return img\n",
    "\n",
    "def pred_and_plot(model,filename,class_names):\n",
    "    img_o = load_and_prep_image(filename)\n",
    "    img = tf.expand_dims(img_o,axis=0)\n",
    "    print(img.shape)\n",
    "    pred = model.predict(img)\n",
    "    print(pred)\n",
    "    if len(pred[0]) > 1:\n",
    "        print('multiclass output')\n",
    "        pred_class = class_names[tf.argmax(pred[0])]\n",
    "    else:\n",
    "        pred_class = class_names[int(tf.round(pred))]\n",
    "    #pred = tf.round(pred[0][0]).numpy()\n",
    "    #pred = int(pred)\n",
    "    #pred_label = class_names[pred]\n",
    "    plt.imshow(img_o)\n",
    "    plt.title(f'Prediction: {pred_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eafd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(model,'03-steak.jpeg',CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbcdd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(model,'03-pizza-dad.jpeg',CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe6b29",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22490102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_trained_model_multiclass_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3905a28",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6835bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('saved_trained_model_multiclass_classification/')\n",
    "loaded_model.evaluate(classification.get_test_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
