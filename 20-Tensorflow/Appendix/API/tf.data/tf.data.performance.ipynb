{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db6ccf2",
   "metadata": {},
   "source": [
    "# Better Performance with tf.data API\n",
    "\n",
    "GPU and TPU can reduce the time required to execute a single training step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd00a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# artificial dataset\n",
    "class ArtificialDataset(tf.data.Dataset):\n",
    "    \n",
    "    def _generator(num_samples):\n",
    "        # open the file simulation\n",
    "        time.sleep(0.03)\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            # simulate reading a line from file\n",
    "            time.sleep(0.015)\n",
    "            yield (sample_idx,)\n",
    "            \n",
    "    def __new__(cls,num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "        cls._generator,\n",
    "        output_signature= tf.TensorSpec(shape=(1,),dtype=tf.int64),\n",
    "        args=(num_samples,))\n",
    "\n",
    "# dummy training loop\n",
    "def benchmark(dataset,num_of_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_of_epochs):\n",
    "        for sample in dataset:\n",
    "            # simulate  a training step\n",
    "            time.sleep(0.01)\n",
    "    print(\"Execution time :\",time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa364ff",
   "metadata": {},
   "source": [
    "## Naive approach\n",
    "\n",
    "In the naive approach the execution happens in **synchronous mode**. When pipeline fetches the data the model is sitting idle and when the model executes the pipeline sits idele. The training time is sum of pipeline opening, reading and training times as below:\n",
    "\n",
    "![SequentialExecution](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/Appendix/API/tf.data/tf.data.sequential.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time : 0.40446649999999984\n"
     ]
    }
   ],
   "source": [
    "# naive approach.\n",
    "benchmark(ArtificialDataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ac216",
   "metadata": {},
   "source": [
    "## Prefetching\n",
    "\n",
    "Prefetching overlaps preprocessing and model execution of a training step. While the model is executing training step's, the input pipeline is reading data for step + 1. \n",
    "\n",
    "The prefetch transformation decouple the time when data is produced from the time data is consumed. The number of elements to prefetch should be equal to number of batches consumed by training step. This value can be tuned manually or set it to **tf.data.AUTOTUNE** which will prompt the runtime to tune the value dynamically at runtime.\n",
    "\n",
    "![Prefetching](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/Appendix/API/tf.data/tf.data.prefetching.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30c6421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time : 0.30005549999999914\n"
     ]
    }
   ],
   "source": [
    "# prefetching\n",
    "benchmark(ArtificialDataset().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f310ec0",
   "metadata": {},
   "source": [
    "## Sequential Interleave\n",
    "\n",
    "Data preparation in sequence.\n",
    "\n",
    "![Sequential Interleave](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/Appendix/API/tf.data/tf.data.performance.seq.interleave.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed16789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time : 0.6885343000000148\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(lambda _: ArtificialDataset())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c5c0f",
   "metadata": {},
   "source": [
    "## Parallel Interleave\n",
    "\n",
    "Data preparation in parallel\n",
    "![Parallel Interleave](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/Appendix/API/tf.data/tf.data.performance.prallel.interleave.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ca1ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time : 0.367986099999996\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(\n",
    "        lambda _: ArtificialDataset(),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35061ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da37d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
