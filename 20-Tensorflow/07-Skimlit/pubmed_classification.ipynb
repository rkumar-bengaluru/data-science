{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a532c6d",
   "metadata": {
    "id": "6a532c6d"
   },
   "source": [
    "# Pubmed sequential sentence classification\n",
    "\n",
    "* Research Paper - https://arxiv.org/abs/1710.06071"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c67a8",
   "metadata": {
    "id": "a93c67a8"
   },
   "source": [
    "## Goal - (255 - 256)\n",
    "\n",
    "* Download a text dataset (PubMed 200K RCT)\n",
    "* Write a preprocessing function for our test data\n",
    "* One Hot Encoding & Label Encoding.\n",
    "* Setting up multiple modelling experiments with different levels of embedding\n",
    "* Building a **multimodal model** to take in different sources of data\n",
    "  * Replicating the model discussed in this paper (https://arxiv.org/abs/1710.06071)\n",
    "  * Actual model description (https://arxiv.org/abs/1612.05251)\n",
    "* Finding the most wrong predictions\n",
    "* Reference Model\n",
    "\n",
    "![Reference Model](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59c3b7",
   "metadata": {
    "id": "ea59c3b7"
   },
   "source": [
    "## SkimLit Inputs and Outputs (257) - Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bceb91",
   "metadata": {
    "id": "b2bceb91"
   },
   "source": [
    "## Get the data (258 - 259)\n",
    "\n",
    "Download the dataset for pubmed 200K RCT from https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beb35ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5beb35ef",
    "outputId": "7dffb1d6-0628-4e01-fcfc-60e0c749848d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397d30d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "397d30d9",
    "outputId": "122342d2-ebf1-4857-de79-b5f97f542881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 30F4-96C0\n",
      "\n",
      " Directory of C:\\2023\\data-science\\20-Tensorflow\\07-Skimlit\\pubmed-rct\n",
      "\n",
      "04-05-2023  13:08    <DIR>          .\n",
      "01-06-2023  12:59    <DIR>          ..\n",
      "04-05-2023  13:08    <DIR>          PubMed_200k_RCT\n",
      "04-05-2023  13:08    <DIR>          PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
      "04-05-2023  13:08    <DIR>          PubMed_20k_RCT\n",
      "04-05-2023  13:08    <DIR>          PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "04-05-2023  13:08             2,403 README.md\n",
      "               1 File(s)          2,403 bytes\n",
      "               6 Dir(s)  339,619,057,664 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f36bb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33f36bb2",
    "outputId": "b3220877-a240-4ec2-e3d0-6a8cbd54188c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# root data directory\n",
    "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
    "# list of file names\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23605a6",
   "metadata": {
    "id": "d23605a6"
   },
   "source": [
    "### Preprocess Data (260)\n",
    "\n",
    "Write a function which will read each line of the file and create the below structure:\n",
    "\n",
    "```\n",
    "[{ 'line_number' : 0,\n",
    "   'target'  : 'first few characters till \\t tab character',\n",
    "   'text'   : 'full text after \\t character till end of line character \\n',\n",
    "   'total_lines' : \n",
    " },\n",
    " ...\n",
    "]\n",
    "```\n",
    "\n",
    "Ignore line starting with ### and repeat the same for train_data, validation_data and test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11189c0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11189c0b",
    "outputId": "11110a36-2f53-41f8-bf1a-95b33dc38f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train lines is 210040\n",
      "size of validation lines is 35212\n",
      "size of test lines is 35135\n",
      "size of train data is 180040\n",
      "size of validation data is 30212\n",
      "size of test data is 30135\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_lines(file_name):\n",
    "    \"\"\"\n",
    "    Reads the file_name and returns the content of the file as list\n",
    "    \"\"\"\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "validation_lines = get_lines(filenames[0])\n",
    "test_lines = get_lines(filenames[1])\n",
    "train_lines = get_lines(filenames[2])\n",
    "\n",
    "print(f\"size of train lines is {len(train_lines)}\")\n",
    "print(f\"size of validation lines is {len(validation_lines)}\")\n",
    "print(f\"size of test lines is {len(test_lines)}\")\n",
    "\n",
    "def create_data_set(lines):\n",
    "    data = []\n",
    "    items = []\n",
    "    index = 0\n",
    "    for line in lines:\n",
    "        \n",
    "        if line.startswith('\\n'):\n",
    "            for item in items:\n",
    "                item['total_lines'] = index -1\n",
    "                data.append(item)\n",
    "            index = 0\n",
    "            items = []\n",
    "        else:\n",
    "            tokens = line.split('\\t')\n",
    "        \n",
    "            if len(tokens) > 1:\n",
    "                item = {'line_number':index,'target': tokens[0],'text':tokens[1].strip() ,'total_lines' :index}\n",
    "                items.append(item)\n",
    "                index = index + 1\n",
    "    return data\n",
    "\n",
    "train_data = create_data_set(train_lines)\n",
    "validation_data = create_data_set(validation_lines)\n",
    "test_data = create_data_set(test_lines)\n",
    "\n",
    "print(f\"size of train data is {len(train_data)}\")\n",
    "print(f\"size of validation data is {len(validation_data)}\")\n",
    "print(f\"size of test data is {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76907385",
   "metadata": {
    "id": "76907385"
   },
   "source": [
    "### Visualize Data (261)\n",
    "\n",
    "Use pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4870cb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "id": "c4870cb5",
    "outputId": "626d6932-31f2-4d1a-e7fe-0fe667ea0eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of train data\n",
      "   line_number     target                                               text  \\\n",
      "0            0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...   \n",
      "1            1    METHODS  A total of @ patients with primary knee OA wer...   \n",
      "2            2    METHODS  Outcome measures included pain reduction and i...   \n",
      "3            3    METHODS  Pain was assessed using the visual analog pain...   \n",
      "4            4    METHODS  Secondary outcome measures included the Wester...   \n",
      "\n",
      "   total_lines  \n",
      "0           11  \n",
      "1           11  \n",
      "2           11  \n",
      "3           11  \n",
      "4           11  \n",
      "unique counts of each target\n",
      "METHODS        59353\n",
      "RESULTS        57953\n",
      "CONCLUSIONS    27168\n",
      "BACKGROUND     21727\n",
      "OBJECTIVE      13839\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data with data frame.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df   = pd.DataFrame(validation_data)\n",
    "test_df  = pd.DataFrame(test_data)\n",
    "# print the head\n",
    "print('head of train data')\n",
    "print(train_df.head())\n",
    "print('unique counts of each target')\n",
    "print(train_df['target'].value_counts())\n",
    "# length of different lines\n",
    "train_df.total_lines.plot.hist();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6b8de9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e6b8de9",
    "outputId": "a84df29a-92e5-46cf-ba82-982f78a1769d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences length 180040\n",
      "val sentences length 30212\n",
      "test sentences length 30135\n"
     ]
    }
   ],
   "source": [
    "# convert to list\n",
    "train_sentences = train_df['text'].tolist()\n",
    "val_sentences   = val_df['text'].tolist()\n",
    "test_sentences  = test_df['text'].tolist()\n",
    "print(f\"train sentences length {len(train_sentences)}\")\n",
    "print(f\"val sentences length {len(val_sentences)}\")\n",
    "print(f\"test sentences length {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbbd61",
   "metadata": {
    "id": "53fbbd61"
   },
   "source": [
    "## One Hot Encoding & Label Encoding (262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9366ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d9366ae",
    "outputId": "909a8032-76ee-43b6-820a-777f5644b759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding\n",
      "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64)\n",
      "label encoding...\n",
      "3 0 0\n",
      "classnames\n",
      "class name =  ['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS'] length of classes = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rupak\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Rupak\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "train_label_one_hot = tf.constant(onehot.fit_transform(train_df['target'].to_numpy().reshape(-1,1)))\n",
    "val_label_one_hot    = tf.constant(onehot.transform(val_df['target'].to_numpy().reshape(-1,1)))\n",
    "test_label_one_hot   = tf.constant(onehot.transform(test_df['target'].to_numpy().reshape(-1,1)))\n",
    "print('one hot encoding')\n",
    "print(train_label_one_hot[0],val_label_one_hot[0],test_label_one_hot[0])\n",
    "\n",
    "# label encoder\n",
    "labelencode = LabelEncoder()\n",
    "train_label_encoded = labelencode.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
    "val_label_encoded = labelencode.transform(val_df['target'].to_numpy().reshape(-1,1))\n",
    "test_label_encoded = labelencode.transform(test_df['target'].to_numpy().reshape(-1,1))\n",
    "print('label encoding...')\n",
    "print(train_label_encoded[0],val_label_encoded[0],test_label_encoded[0])\n",
    "\n",
    "print('classnames')\n",
    "classnames = labelencode.classes_\n",
    "print('class name = ', classnames, 'length of classes =', len(classnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67375053",
   "metadata": {
    "id": "67375053"
   },
   "source": [
    "## Experiments to be Conducted (262)\n",
    "\n",
    "![Experiments](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/experiments.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb022b8",
   "metadata": {
    "id": "1cb022b8"
   },
   "source": [
    "## Model 0 - Naive Bayes with TF-IDF Encoder (263)\n",
    "\n",
    "* Selection Method\n",
    "![Machine Learning Map](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/ml_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ea3376",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94ea3376",
    "outputId": "5ac04c2c-a1e1-4378-8295-7a96c40dd036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.7218323844829869, 'precision_score': 0.7186466952323352, 'recall_score': 0.7218323844829869, 'f1_score': 0.6989250353450294}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "def find_scores(val_label_encoded,val_preds):\n",
    "    a_score = accuracy_score(y_true=val_label_encoded,y_pred=val_preds)\n",
    "    p_score = precision_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
    "    r_score = recall_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
    "    f_score = f1_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
    "    return {'accuracy_score' : a_score, \n",
    "            'precision_score' : p_score, \n",
    "            'recall_score' : r_score,\n",
    "            'f1_score' : f_score}\n",
    "\n",
    "model_0 = Pipeline([('tf-idf',TfidfVectorizer()),\n",
    "               ('naive_bayes',MultinomialNB())])\n",
    "model_0.fit(X=train_sentences,y=train_label_encoded)\n",
    "\n",
    "y_pred = model_0.score(X=val_sentences,y=val_label_encoded)\n",
    "\n",
    "val_preds = model_0.predict(val_sentences)\n",
    "model_0_results = find_scores(val_label_encoded,val_preds)\n",
    "print(model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52108425",
   "metadata": {
    "id": "52108425"
   },
   "source": [
    "## Model 1 - Conv1D with token Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83b74b",
   "metadata": {
    "id": "4c83b74b"
   },
   "source": [
    "### Data Visualization (264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2553b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "e2553b19",
    "outputId": "1bd122da-0eef-49ba-ff12-20bc9883acbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tokens in each sentences  26.338269273494777\n",
      "no of tokens to keep to cover 95% of the sentence tokens in training data is 55\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# find how tokens is each sentences\n",
    "lengths = [len(sen.split()) for sen in train_sentences]\n",
    "print('mean tokens in each sentences ', np.mean(lengths))\n",
    "output_sequence_length = int(np.percentile(lengths,95))\n",
    "# find percentile to cover 95% of the sentence tokens\n",
    "print(f\"no of tokens to keep to cover 95% of the sentence tokens in training data is {output_sequence_length}\")\n",
    "plt.hist(lengths,bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807bbae",
   "metadata": {
    "id": "9807bbae"
   },
   "source": [
    "### Vectorize Tokens (265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01440492",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01440492",
    "outputId": "a1db6d03-8136-441b-e2bc-d67e12f4a423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence Text \n",
      " Both clinical studies were conducted at the GlaxoSmithKline Medicines Research Unit in the Prince of Wales Hospital , Sydney , Australia .\n",
      "\n",
      "length of the Sample Sentence 138\n",
      "Vectorized Sample Sentence\n",
      " [[   54    47   202     9   198    15     2  7516  4579   285   835     5\n",
      "      2 29081     4  6452   237  8171  1696     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "total no of words in the vocabulary is 64841\n",
      "most common words in the vocabulary is \n",
      " ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']\n",
      "least common words in the vocabulary is \n",
      " ['aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n",
      "{'name': 'text_vectorization', 'trainable': True, 'batch_input_shape': (None,), 'dtype': 'string', 'max_tokens': 68000, 'standardize': 'lower_and_strip_punctuation', 'split': 'whitespace', 'ngrams': None, 'output_mode': 'int', 'output_sequence_length': 55, 'pad_to_max_tokens': False, 'sparse': False, 'ragged': False, 'vocabulary': None, 'idf_weights': None}\n"
     ]
    }
   ],
   "source": [
    "# create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_tokens = 68000\n",
    "text_vectorization = TextVectorization(max_tokens=max_tokens,\n",
    "                                      output_sequence_length=output_sequence_length)\n",
    "\n",
    "text_vectorization.adapt(train_sentences)\n",
    "\n",
    "# check the output of text vectorization\n",
    "import random\n",
    "sample_sentence = random.choice(train_sentences)\n",
    "print(f\"Sample Sentence Text \\n {sample_sentence}\\n\")\n",
    "print(f\"length of the Sample Sentence {len(sample_sentence)}\")\n",
    "print(f\"Vectorized Sample Sentence\\n {text_vectorization([sample_sentence])}\")\n",
    "\n",
    "# how many words in our vocabulary\n",
    "rct_20k_text_vocab = text_vectorization.get_vocabulary()\n",
    "print(f\"total no of words in the vocabulary is {len(rct_20k_text_vocab)}\")\n",
    "print(f\"most common words in the vocabulary is \\n {rct_20k_text_vocab[:10]}\")\n",
    "print(f\"least common words in the vocabulary is \\n {rct_20k_text_vocab[-10:]}\")\n",
    "\n",
    "# print text vectorization config\n",
    "t_config = text_vectorization.get_config()\n",
    "print(t_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b911e8",
   "metadata": {
    "id": "c0b911e8"
   },
   "source": [
    "### Token Embedding (266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e22319f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e22319f",
    "outputId": "0f0fe60a-ae2f-4494-8190-101190c8e14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before embedding \n",
      " Both clinical studies were conducted at the GlaxoSmithKline Medicines Research Unit in the Prince of Wales Hospital , Sydney , Australia .\n",
      "vectorized sentence \n",
      " [[   54    47   202     9   198    15     2  7516  4579   285   835     5\n",
      "      2 29081     4  6452   237  8171  1696     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "embedded sentence \n",
      " [[[ 0.04731205 -0.03871269  0.03297079 ... -0.02930509  0.01914233\n",
      "    0.03889399]\n",
      "  [ 0.02497282 -0.01576455  0.00139964 ...  0.01730626 -0.01024384\n",
      "   -0.04992795]\n",
      "  [-0.0273163   0.04136432  0.04686265 ... -0.04200624  0.02208252\n",
      "    0.03750518]\n",
      "  ...\n",
      "  [-0.02488676  0.01915764  0.02513603 ...  0.01253928  0.00984005\n",
      "   -0.04096913]\n",
      "  [-0.02488676  0.01915764  0.02513603 ...  0.01253928  0.00984005\n",
      "   -0.04096913]\n",
      "  [-0.02488676  0.01915764  0.02513603 ...  0.01253928  0.00984005\n",
      "   -0.04096913]]]\n",
      "embedded sentence shape \n",
      " (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# add a embedding layer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(input_dim=len(rct_20k_text_vocab),\n",
    "                 output_dim=128,\n",
    "                  mask_zero=True,\n",
    "                  name='token_embedding')\n",
    "# token embedding\n",
    "print(f\"Sentence before embedding \\n {sample_sentence}\")\n",
    "vectorized_sentence = text_vectorization([sample_sentence])\n",
    "print(f\"vectorized sentence \\n {vectorized_sentence}\")\n",
    "embed_sentence = embedding_layer(vectorized_sentence)\n",
    "print(f\"embedded sentence \\n {embed_sentence}\")\n",
    "print(f\"embedded sentence shape \\n {embed_sentence.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d954fa5",
   "metadata": {
    "id": "1d954fa5"
   },
   "source": [
    "## Create Dataset using tf.data.Dataset (267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b0e2b0",
   "metadata": {
    "id": "86b0e2b0"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_label_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences,val_label_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences,test_label_one_hot))\n",
    "\n",
    "# for fast performance \n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset  = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1280fc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1280fc6",
    "outputId": "5b495930-e30c-423f-882c-7034585cf069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40beeb95",
   "metadata": {
    "id": "40beeb95"
   },
   "source": [
    "## Build Conv1D model (268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bde1b93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bde1b93",
    "outputId": "050adf56-ea09-4b7b-f093-aa72ef44c9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " vectorization_layer (TextVe  (None, 55)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " token_embedding_layer (Embe  (None, 55, 128)          8299648   \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " conv1d_Layer (Conv1D)       (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling (Glo  (None, 64)               0         \n",
      " balAveragePooling1D)                                            \n",
      "                                                                 \n",
      " fully_connected (Dense)     (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Input, TextVectorization, Embedding,Dense\n",
    "\n",
    "# input layer\n",
    "inputs = Input(shape=(1,),dtype=tf.string,name=\"input\")\n",
    "# text vectorization layer\n",
    "max_tokens = 68000\n",
    "lengths = [len(sen.split()) for sen in train_sentences]\n",
    "output_sequence_length = int(np.percentile(lengths,95))\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
    "                      output_sequence_length=output_sequence_length,\n",
    "                                   name=\"vectorization_layer\")\n",
    "text_vectorizer.adapt(train_sentences)\n",
    "vectors = text_vectorizer(inputs)\n",
    "# embedding layer\n",
    "embedding = Embedding(input_dim=len(rct_20k_text_vocab),\n",
    "                     output_dim=128,\n",
    "                     mask_zero=True,\n",
    "                      name=\"token_embedding_layer\")\n",
    "token_embedding = embedding(vectors)\n",
    "# conv1d layer\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=5,\n",
    "          padding=\"same\",\n",
    "          activation=\"relu\",\n",
    "          name=\"conv1d_Layer\")(token_embedding)\n",
    "# average pooling\n",
    "x = GlobalAveragePooling1D(name=\"global_average_pooling\")(x)\n",
    "# output layer\n",
    "outputs = Dense(5,activation=\"softmax\", name=\"fully_connected\")(x)\n",
    "# finally the model\n",
    "model_1 = Model(inputs,outputs)\n",
    "\n",
    "# compile the model\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "# summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "258d5d14",
   "metadata": {
    "id": "258d5d14"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit_the_model(model):\n",
    "    \n",
    "    # fit the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_dataset,\n",
    "                             steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                              epochs=3,\n",
    "                             validation_data=val_dataset,\n",
    "                             validation_steps=int(0.1*len(val_dataset)))\n",
    "    time_taken = time.time() - start_time\n",
    "    print(f\"time taken to fit {time_taken}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdeb7258",
   "metadata": {
    "id": "bdeb7258"
   },
   "outputs": [],
   "source": [
    "# let's try with cpu\n",
    "#with tf.device(\"/cpu:0\"):\n",
    "#    fit_the_model(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af51073f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af51073f",
    "outputId": "f8e1009b-58e0-47cb-e647-13605d1db90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 30s 51ms/step - loss: 0.9187 - accuracy: 0.6360 - val_loss: 0.6932 - val_accuracy: 0.7344\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.6638 - accuracy: 0.7512 - val_loss: 0.6368 - val_accuracy: 0.7699\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 28s 50ms/step - loss: 0.6201 - accuracy: 0.7730 - val_loss: 0.5972 - val_accuracy: 0.7829\n",
      "time taken to fit 86.64157629013062\n"
     ]
    }
   ],
   "source": [
    "# with gpu\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    fit_the_model(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6467abc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6467abc4",
    "outputId": "d324092e-7856-4677-89aa-e3decec22aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.5984 - accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5983775854110718, 0.7850192189216614]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evalue the model\n",
    "model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f0d4c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8f0d4c4",
    "outputId": "b5740d7d-f7e9-47d4-bcda-e890f763b8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4.6639949e-01, 1.7271149e-01, 5.1625654e-02, 2.8174546e-01,\n",
       "         2.7517878e-02],\n",
       "        [4.2332375e-01, 3.2791874e-01, 9.4140954e-03, 2.3243329e-01,\n",
       "         6.9101942e-03],\n",
       "        [1.7993249e-01, 7.0139817e-03, 1.6044464e-03, 8.1142735e-01,\n",
       "         2.1657374e-05],\n",
       "        ...,\n",
       "        [7.6109059e-06, 8.3144312e-04, 1.2618448e-03, 4.1022849e-06,\n",
       "         9.9789500e-01],\n",
       "        [4.6031188e-02, 4.6744037e-01, 6.3116454e-02, 4.4023819e-02,\n",
       "         3.7938818e-01],\n",
       "        [1.8786760e-01, 6.4609623e-01, 5.9940394e-02, 5.0801132e-02,\n",
       "         5.5294614e-02]], dtype=float32),\n",
       " (30212, 5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_dataset)\n",
    "model_1_pred_probs,model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "812bd5af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "812bd5af",
    "outputId": "cc0e96b6-5607-40b8-f9e8-6d18b2fce2ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = tf.argmax(model_1_pred_probs,axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96d569f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96d569f5",
    "outputId": "fbf5c15a-ef6c-4ccb-eb74-f0680d93d06b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy_score': 0.7218323844829869,\n",
       "  'precision_score': 0.7186466952323352,\n",
       "  'recall_score': 0.7218323844829869,\n",
       "  'f1_score': 0.6989250353450294},\n",
       " {'accuracy_score': 0.7850191976698001,\n",
       "  'precision_score': 0.781880412238866,\n",
       "  'recall_score': 0.7850191976698001,\n",
       "  'f1_score': 0.7826315676944716})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = find_scores(val_label_encoded,model_1_preds)\n",
    "model_0_results,model_1_results,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a3f58",
   "metadata": {
    "id": "459a3f58"
   },
   "source": [
    "## Model 2 Architecture - Tensorflow Hub Pretrained Feature Extractor (269 - 270)\n",
    "![Model 2 Architecture](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/model_2_architecture.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e13d93ab",
   "metadata": {
    "id": "e13d93ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Rupak\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     use \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m     universal_sentence_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muniversal_encoder_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:146\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_shape:\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;66;03m# Autograph chokes on _convert_nest_to_shapes(), so we call it here\u001b[39;00m\n\u001b[0;32m    142\u001b[0m   \u001b[38;5;66;03m# and not from within call().\u001b[39;00m\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    144\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument \u001b[38;5;241m=\u001b[39m func_has_training_argument(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:398\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    396\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_hub\\module_v2.py:102\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_hub_module_v1:\n\u001b[0;32m    101\u001b[0m     tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 102\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:800\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    799\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 800\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:905\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    901\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    904\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 905\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    909\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Rupak\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    use = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "    universal_sentence_encoder = hub.KerasLayer(use,\n",
    "                              trainable=False,\n",
    "                              name='universal_encoder_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c17726",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2c17726",
    "outputId": "fa48c945-dbe2-42f1-ef1a-c22a47205eab"
   },
   "outputs": [],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"random sentence to encode with hub encoder \\n {random_sentence}\")\n",
    "random_sentence_encoded = universal_sentence_encoder([random_sentence])\n",
    "print(f\"shape of encoded sentence {random_sentence_encoded.shape}\")\n",
    "print(f\"encoded sentence \\n {random_sentence_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10e4bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc10e4bd",
    "outputId": "36b12151-80d0-4690-fd4e-b665711f3d45"
   },
   "outputs": [],
   "source": [
    "# create model 2\n",
    "inputs = Input(shape=[],dtype=tf.string,name='input_layer')\n",
    "pretrained_embedding = universal_sentence_encoder(inputs)\n",
    "dense = Dense(128,activation='relu',name='fully_connected_layer')(pretrained_embedding)\n",
    "outputs = Dense(5,activation='softmax',name='output_layer')(dense)\n",
    "model_2 = Model(inputs=inputs,\n",
    "               outputs=outputs,\n",
    "               name='model_2_use_feature_extractor')\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c649ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1c649ed",
    "outputId": "6dff59c8-9a07-4f96-a0b3-3eaa49f5544c"
   },
   "outputs": [],
   "source": [
    "model_2_history = fit_the_model(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa169b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eaa169b",
    "outputId": "5a8bf13c-013a-4d04-9254-1d89efe1341b"
   },
   "outputs": [],
   "source": [
    "model_2.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ea285",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f5ea285",
    "outputId": "44f21f20-1113-4275-8bfa-ae8c44a52f49"
   },
   "outputs": [],
   "source": [
    "model_2_pred_probs = model_2.predict(val_dataset)\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d25f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "549d25f5",
    "outputId": "2164f808-22df-416e-b0c2-18364c58db5e"
   },
   "outputs": [],
   "source": [
    "model_2_pred = tf.argmax(model_2_pred_probs,axis=1)\n",
    "model_2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c8e23",
   "metadata": {
    "id": "827c8e23"
   },
   "outputs": [],
   "source": [
    "model_2_results = find_scores(val_label_encoded,model_2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a37bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "801a37bb",
    "outputId": "b0a2c232-c367-4989-ea19-b8fa28db7b93"
   },
   "outputs": [],
   "source": [
    "model_2_results,model_1_results,model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53053f8",
   "metadata": {
    "id": "b53053f8"
   },
   "source": [
    "## Model-3 : Conv1D with character embedding\n",
    "\n",
    "![Model 3 Architecture](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/model_3_architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b796f",
   "metadata": {
    "id": "225b796f"
   },
   "source": [
    "### Character Embedding Layer (271 - 272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96334d88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "96334d88",
    "outputId": "f9a6dc79-9da0-424a-c32c-f67a12b0b6cc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.data import Dataset\n",
    "# prepare data\n",
    "def split_chars(sentence):\n",
    "    return ' '.join(list(sentence))\n",
    "\n",
    "\n",
    "training_char_sentences = [split_chars(sentence.lower()) for sentence in train_sentences]\n",
    "val_char_sentences      = [split_chars(sentence.lower()) for sentence in val_sentences]\n",
    "test_char_sentences     = [split_chars(sentence.lower()) for sentence in test_sentences]\n",
    "training_char_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KKm_wY2uI-p4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKm_wY2uI-p4",
    "outputId": "db626559-764e-46d3-b1bf-76a2fd341f03"
   },
   "outputs": [],
   "source": [
    "len(train_sentences[0]), len(training_char_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hf0LOrSjiTsq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf0LOrSjiTsq",
    "outputId": "23ff8044-2bb4-4445-9444-c470531aac4d"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb3e97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2eb3e97",
    "outputId": "7976e7aa-3750-41fc-f94a-199b79ff391a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.data import Dataset\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "lengths_of_sentences = [len(sentence) for sentence in training_char_sentences]\n",
    "# find no of tokens to take to cover 95 % of the data\n",
    "max_length = int(np.percentile(lengths_of_sentences,95)) # sequence length to pad the outputs to\n",
    "print(f\"number of tokens to consider {max_length} \")\n",
    "# find vocab length\n",
    "all_printable = string.ascii_lowercase + string.digits + string.punctuation\n",
    "max_features = len(all_printable); # no of characters in the vocabulary\n",
    "char_vectorizer = TextVectorization(max_tokens=max_features,\n",
    "                                   output_sequence_length=max_length,\n",
    "                                   name='character_vectorization')\n",
    "\n",
    "#test_char_dataset  = Dataset.from_tensor_slices((test_char_sentences,test_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "char_vectorizer.adapt(training_char_sentences)\n",
    "vocab = char_vectorizer.get_vocabulary()\n",
    "sample_char_sentence = random.choice(training_char_sentences)\n",
    "print(f\"vocabulary \\n {vocab}\")\n",
    "print(f\"vocabulary length \\n {len(vocab)}\")\n",
    "sample_sentence_encoded = char_vectorizer([sample_char_sentence])\n",
    "print(f\"encoded random sample \\n {sample_sentence_encoded}\")\n",
    "print(f\"shape of encoded sample char sentence \\n {sample_sentence_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b39041",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0b39041",
    "outputId": "7cc1b1c2-8e30-4e2a-df2d-1a1d2052df03"
   },
   "outputs": [],
   "source": [
    "# embedding layer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "char_embedding = Embedding(input_dim=len(vocab),\n",
    "                          output_dim=25,\n",
    "                          mask_zero=True,\n",
    "                          name='char_embedding_layer')\n",
    "char_embedding_sample = char_embedding(sample_sentence_encoded)\n",
    "char_embedding_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd96d1c",
   "metadata": {
    "id": "1fd96d1c"
   },
   "source": [
    "### Create Full Model (273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6425b",
   "metadata": {
    "id": "f3e6425b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "inputs = Input(shape=(1,),dtype=tf.string,name='input_layer')\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embedding(char_vectors)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=5,\n",
    "          padding='same',\n",
    "          activation='relu',\n",
    "          name='conv_1d_layer')(char_embeddings)\n",
    "x = GlobalMaxPooling1D(name='GlobalAveragePooling1D')(x)\n",
    "outputs = Dense(units=5,activation='softmax',name='full_connected')(x)\n",
    "model_3 = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614ad44",
   "metadata": {
    "id": "8614ad44"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "               optimizer=Adam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6c19c",
   "metadata": {
    "id": "fbd6c19c"
   },
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5eabe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a5eabe4",
    "outputId": "88d604f7-ab4d-4323-9d03-163868f41495"
   },
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507958c7",
   "metadata": {
    "id": "507958c7"
   },
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886041e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "886041e2",
    "outputId": "e84f466c-3940-401b-ad9b-fb82c8115dd8"
   },
   "outputs": [],
   "source": [
    "train_char_dataset = Dataset.from_tensor_slices((training_char_sentences,train_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset   = Dataset.from_tensor_slices((val_char_sentences,val_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XeZqWo04L0GJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeZqWo04L0GJ",
    "outputId": "a5f874af-5cb3-4ee3-e5c0-b68cf0c94d53"
   },
   "outputs": [],
   "source": [
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data = val_char_dataset,\n",
    "                              validation_steps=int(0.1* len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dea307",
   "metadata": {
    "id": "08dea307"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdea782",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fdea782",
    "outputId": "d6d70add-8fda-45f2-836b-2fe61bc29017"
   },
   "outputs": [],
   "source": [
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qR8YlESUMUPa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qR8YlESUMUPa",
    "outputId": "ef698c03-ce94-490a-a0ea-d83c1dca59f8"
   },
   "outputs": [],
   "source": [
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kZvjJ1bdMeEh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZvjJ1bdMeEh",
    "outputId": "a76aab34-8ed2-4b5f-8cc1-e29d3fcc2ac0"
   },
   "outputs": [],
   "source": [
    "model_3_preds = tf.argmax(model_3_pred_probs,axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4wpD5udUMmHj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wpD5udUMmHj",
    "outputId": "a3309329-e6a7-4ac3-b530-7b1e761405a5"
   },
   "outputs": [],
   "source": [
    "model_3_results = find_scores(val_label_encoded,model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a858483",
   "metadata": {
    "id": "pr-qyPsHMyf_"
   },
   "source": [
    "## Model 4 - Combine Token Embedding and Character Embedding (274 - 278)\n",
    "\n",
    "* Create token embedding using pretrained model.\n",
    "* Create character embedding \n",
    "* Combine token embedding and character embedding with **layers.Concatenate**\n",
    "* Build a series of output layer on top of Concatenated layer.\n",
    "* Construct a model which takes token and character level sequences as input and produces sequence label prbabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459775a1",
   "metadata": {},
   "source": [
    "### Prepare Data for Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e10200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_file = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt'\n",
    "val_file = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt'\n",
    "test_file = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt'\n",
    "\n",
    "def create_data_for_model4(file_to_load):\n",
    "    lines = open(file_to_load,'r').readlines()\n",
    "    data = []\n",
    "    line_number = 0\n",
    "    abstract_lines = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('###'):\n",
    "            abstract_lines = \"\"\n",
    "        elif line.isspace():\n",
    "            # do the \n",
    "            all_abstract = abstract_lines.splitlines()\n",
    "            line_number = 0\n",
    "            for abstract in all_abstract:\n",
    "                splits = abstract.split('\\t')\n",
    "                target,text = splits[0],splits[1]\n",
    "                total_lines = len(all_abstract) -1\n",
    "                data.append({'line_number' : line_number,\n",
    "                            'target' : target,\n",
    "                            'text': text.lower(),\n",
    "                            'total_lines': total_lines})\n",
    "                line_number = line_number + 1\n",
    "        else:\n",
    "            abstract_lines += line\n",
    "    return data\n",
    "            \n",
    "train_sentences_model4 = create_data_for_model4(train_file)\n",
    "val_sentences_model4 = create_data_for_model4(val_file)\n",
    "test_sentences_model4 = create_data_for_model4(test_file)\n",
    "# create dataframe\n",
    "train_df_model4 = pd.DataFrame(train_sentences_model4)\n",
    "val_df_model4 = pd.DataFrame(val_sentences_model4)\n",
    "test_df_model4 = pd.DataFrame(test_sentences_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b495853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorflow dataset\n",
    "train_df_model4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264f90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
