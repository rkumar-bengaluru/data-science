{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a532c6d",
      "metadata": {
        "id": "6a532c6d"
      },
      "source": [
        "# Pubmed sequential sentence classification\n",
        "\n",
        "* Research Paper - https://arxiv.org/abs/1710.06071"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93c67a8",
      "metadata": {
        "id": "a93c67a8"
      },
      "source": [
        "## Goal - (255 - 256)\n",
        "\n",
        "* Download a text dataset (PubMed 200K RCT)\n",
        "* Write a preprocessing function for our test data\n",
        "* One Hot Encoding & Label Encoding.\n",
        "* Setting up multiple modelling experiments with different levels of embedding\n",
        "* Building a **multimodal model** to take in different sources of data\n",
        "  * Replicating the model discussed in this paper (https://arxiv.org/abs/1710.06071)\n",
        "  * Actual model description (https://arxiv.org/abs/1612.05251)\n",
        "* Finding the most wrong predictions\n",
        "* Reference Model\n",
        "\n",
        "![Reference Model](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/model.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea59c3b7",
      "metadata": {
        "id": "ea59c3b7"
      },
      "source": [
        "## SkimLit Inputs and Outputs (257) - Ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2bceb91",
      "metadata": {
        "id": "b2bceb91"
      },
      "source": [
        "## Get the data (258 - 259)\n",
        "\n",
        "Download the dataset for pubmed 200K RCT from https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "5beb35ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5beb35ef",
        "outputId": "7dffb1d6-0628-4e01-fcfc-60e0c749848d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "397d30d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397d30d9",
        "outputId": "122342d2-ebf1-4857-de79-b5f97f542881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ],
      "source": [
        "!dir pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "33f36bb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33f36bb2",
        "outputId": "b3220877-a240-4ec2-e3d0-6a8cbd54188c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# root data directory\n",
        "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
        "# list of file names\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "print(filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d23605a6",
      "metadata": {
        "id": "d23605a6"
      },
      "source": [
        "### Preprocess Data (260)\n",
        "\n",
        "Write a function which will read each line of the file and create the below structure:\n",
        "\n",
        "```\n",
        "[{ 'line_number' : 0,\n",
        "   'target'  : 'first few characters till \\t tab character',\n",
        "   'text'   : 'full text after \\t character till end of line character \\n',\n",
        "   'total_lines' : \n",
        " },\n",
        " ...\n",
        "]\n",
        "```\n",
        "\n",
        "Ignore line starting with ### and repeat the same for train_data, validation_data and test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "11189c0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11189c0b",
        "outputId": "11110a36-2f53-41f8-bf1a-95b33dc38f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of train lines is 210040\n",
            "size of validation lines is 35212\n",
            "size of test lines is 35135\n",
            "size of train data is 180040\n",
            "size of validation data is 30212\n",
            "size of test data is 30135\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_lines(file_name):\n",
        "    \"\"\"\n",
        "    Reads the file_name and returns the content of the file as list\n",
        "    \"\"\"\n",
        "    with open(file_name) as f:\n",
        "        lines = f.readlines()\n",
        "    return lines\n",
        "\n",
        "validation_lines = get_lines(filenames[0])\n",
        "test_lines = get_lines(filenames[1])\n",
        "train_lines = get_lines(filenames[2])\n",
        "\n",
        "print(f\"size of train lines is {len(train_lines)}\")\n",
        "print(f\"size of validation lines is {len(validation_lines)}\")\n",
        "print(f\"size of test lines is {len(test_lines)}\")\n",
        "\n",
        "def create_data_set(lines):\n",
        "    data = []\n",
        "    items = []\n",
        "    index = 0\n",
        "    for line in lines:\n",
        "        \n",
        "        if line.startswith('\\n'):\n",
        "            for item in items:\n",
        "                item['total_lines'] = index -1\n",
        "                data.append(item)\n",
        "            index = 0\n",
        "            items = []\n",
        "        else:\n",
        "            tokens = line.split('\\t')\n",
        "        \n",
        "            if len(tokens) > 1:\n",
        "                item = {'line_number':index,'target': tokens[0],'text':tokens[1].strip() ,'total_lines' :index}\n",
        "                items.append(item)\n",
        "                index = index + 1\n",
        "    return data\n",
        "\n",
        "train_data = create_data_set(train_lines)\n",
        "validation_data = create_data_set(validation_lines)\n",
        "test_data = create_data_set(test_lines)\n",
        "\n",
        "print(f\"size of train data is {len(train_data)}\")\n",
        "print(f\"size of validation data is {len(validation_data)}\")\n",
        "print(f\"size of test data is {len(test_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76907385",
      "metadata": {
        "id": "76907385"
      },
      "source": [
        "### Visualize Data (261)\n",
        "\n",
        "Use pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "c4870cb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "c4870cb5",
        "outputId": "626d6932-31f2-4d1a-e7fe-0fe667ea0eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head of train data\n",
            "   line_number     target                                               text  \\\n",
            "0            0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...   \n",
            "1            1    METHODS  A total of @ patients with primary knee OA wer...   \n",
            "2            2    METHODS  Outcome measures included pain reduction and i...   \n",
            "3            3    METHODS  Pain was assessed using the visual analog pain...   \n",
            "4            4    METHODS  Secondary outcome measures included the Wester...   \n",
            "\n",
            "   total_lines  \n",
            "0           11  \n",
            "1           11  \n",
            "2           11  \n",
            "3           11  \n",
            "4           11  \n",
            "unique counts of each target\n",
            "METHODS        59353\n",
            "RESULTS        57953\n",
            "CONCLUSIONS    27168\n",
            "BACKGROUND     21727\n",
            "OBJECTIVE      13839\n",
            "Name: target, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize data with data frame.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_df = pd.DataFrame(train_data)\n",
        "val_df   = pd.DataFrame(validation_data)\n",
        "test_df  = pd.DataFrame(test_data)\n",
        "# print the head\n",
        "print('head of train data')\n",
        "print(train_df.head())\n",
        "print('unique counts of each target')\n",
        "print(train_df['target'].value_counts())\n",
        "# length of different lines\n",
        "train_df.total_lines.plot.hist();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "1e6b8de9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e6b8de9",
        "outputId": "a84df29a-92e5-46cf-ba82-982f78a1769d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train sentences length 180040\n",
            "val sentences length 30212\n",
            "test sentences length 30135\n"
          ]
        }
      ],
      "source": [
        "# convert to list\n",
        "train_sentences = train_df['text'].tolist()\n",
        "val_sentences   = val_df['text'].tolist()\n",
        "test_sentences  = test_df['text'].tolist()\n",
        "print(f\"train sentences length {len(train_sentences)}\")\n",
        "print(f\"val sentences length {len(val_sentences)}\")\n",
        "print(f\"test sentences length {len(test_sentences)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53fbbd61",
      "metadata": {
        "id": "53fbbd61"
      },
      "source": [
        "## One Hot Encoding & Label Encoding (262)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "0d9366ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9366ae",
        "outputId": "909a8032-76ee-43b6-820a-777f5644b759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one hot encoding\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64)\n",
            "label encoding...\n",
            "3 0 0\n",
            "classnames\n",
            "class name =  ['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS'] length of classes = 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "#tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "onehot = OneHotEncoder(sparse_output=False)\n",
        "train_label_one_hot = tf.constant(onehot.fit_transform(train_df['target'].to_numpy().reshape(-1,1)))\n",
        "val_label_one_hot    = tf.constant(onehot.transform(val_df['target'].to_numpy().reshape(-1,1)))\n",
        "test_label_one_hot   = tf.constant(onehot.transform(test_df['target'].to_numpy().reshape(-1,1)))\n",
        "print('one hot encoding')\n",
        "print(train_label_one_hot[0],val_label_one_hot[0],test_label_one_hot[0])\n",
        "\n",
        "# label encoder\n",
        "labelencode = LabelEncoder()\n",
        "train_label_encoded = labelencode.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
        "val_label_encoded = labelencode.transform(val_df['target'].to_numpy().reshape(-1,1))\n",
        "test_label_encoded = labelencode.transform(test_df['target'].to_numpy().reshape(-1,1))\n",
        "print('label encoding...')\n",
        "print(train_label_encoded[0],val_label_encoded[0],test_label_encoded[0])\n",
        "\n",
        "print('classnames')\n",
        "classnames = labelencode.classes_\n",
        "print('class name = ', classnames, 'length of classes =', len(classnames))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67375053",
      "metadata": {
        "id": "67375053"
      },
      "source": [
        "## Experiments to be Conducted (262)\n",
        "\n",
        "![Experiments](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/experiments.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cb022b8",
      "metadata": {
        "id": "1cb022b8"
      },
      "source": [
        "## Model 0 - Naive Bayes with TF-IDF Encoder (263)\n",
        "\n",
        "* Selection Method\n",
        "![Machine Learning Map](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/ml_map.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "94ea3376",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ea3376",
        "outputId": "5ac04c2c-a1e1-4378-8295-7a96c40dd036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy_score': 0.7218323844829869, 'precision_score': 0.7186466952323352, 'recall_score': 0.7218323844829869, 'f1_score': 0.6989250353450294}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "def find_scores(val_label_encoded,val_preds):\n",
        "    a_score = accuracy_score(y_true=val_label_encoded,y_pred=val_preds)\n",
        "    p_score = precision_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
        "    r_score = recall_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
        "    f_score = f1_score(y_true=val_label_encoded,y_pred=val_preds,average='weighted')\n",
        "    return {'accuracy_score' : a_score, \n",
        "            'precision_score' : p_score, \n",
        "            'recall_score' : r_score,\n",
        "            'f1_score' : f_score}\n",
        "\n",
        "model_0 = Pipeline([('tf-idf',TfidfVectorizer()),\n",
        "               ('naive_bayes',MultinomialNB())])\n",
        "model_0.fit(X=train_sentences,y=train_label_encoded)\n",
        "\n",
        "y_pred = model_0.score(X=val_sentences,y=val_label_encoded)\n",
        "\n",
        "val_preds = model_0.predict(val_sentences)\n",
        "model_0_results = find_scores(val_label_encoded,val_preds)\n",
        "print(model_0_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52108425",
      "metadata": {
        "id": "52108425"
      },
      "source": [
        "## Model 1 - Conv1D with token Embedding "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c83b74b",
      "metadata": {
        "id": "4c83b74b"
      },
      "source": [
        "### Data Visualization (264)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "e2553b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "e2553b19",
        "outputId": "1bd122da-0eef-49ba-ff12-20bc9883acbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean tokens in each sentences  26.338269273494777\n",
            "no of tokens to keep to cover 95% of the sentence tokens in training data is 55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# find how tokens is each sentences\n",
        "lengths = [len(sen.split()) for sen in train_sentences]\n",
        "print('mean tokens in each sentences ', np.mean(lengths))\n",
        "output_sequence_length = int(np.percentile(lengths,95))\n",
        "# find percentile to cover 95% of the sentence tokens\n",
        "print(f\"no of tokens to keep to cover 95% of the sentence tokens in training data is {output_sequence_length}\")\n",
        "plt.hist(lengths,bins=10);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9807bbae",
      "metadata": {
        "id": "9807bbae"
      },
      "source": [
        "### Vectorize Tokens (265)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "01440492",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01440492",
        "outputId": "a1db6d03-8136-441b-e2bc-d67e12f4a423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Sentence Text \n",
            " The image quality and radiation dose of two groups were compared .\n",
            "\n",
            "length of the Sample Sentence 66\n",
            "Vectorized Sample Sentence\n",
            " [[   2 1277  141    3  918  131    4   51   24    9   34    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "total no of words in the vocabulary is 64841\n",
            "most common words in the vocabulary is \n",
            " ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']\n",
            "least common words in the vocabulary is \n",
            " ['aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n",
            "{'name': 'text_vectorization', 'trainable': True, 'dtype': 'string', 'batch_input_shape': (None,), 'max_tokens': 68000, 'standardize': 'lower_and_strip_punctuation', 'split': 'whitespace', 'ngrams': None, 'output_mode': 'int', 'output_sequence_length': 55, 'pad_to_max_tokens': False, 'sparse': False, 'ragged': False, 'vocabulary': None, 'idf_weights': None, 'encoding': 'utf-8', 'vocabulary_size': 64841}\n"
          ]
        }
      ],
      "source": [
        "# create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "max_tokens = 68000\n",
        "text_vectorization = TextVectorization(max_tokens=max_tokens,\n",
        "                                      output_sequence_length=output_sequence_length)\n",
        "\n",
        "text_vectorization.adapt(train_sentences)\n",
        "\n",
        "# check the output of text vectorization\n",
        "import random\n",
        "sample_sentence = random.choice(train_sentences)\n",
        "print(f\"Sample Sentence Text \\n {sample_sentence}\\n\")\n",
        "print(f\"length of the Sample Sentence {len(sample_sentence)}\")\n",
        "print(f\"Vectorized Sample Sentence\\n {text_vectorization([sample_sentence])}\")\n",
        "\n",
        "# how many words in our vocabulary\n",
        "rct_20k_text_vocab = text_vectorization.get_vocabulary()\n",
        "print(f\"total no of words in the vocabulary is {len(rct_20k_text_vocab)}\")\n",
        "print(f\"most common words in the vocabulary is \\n {rct_20k_text_vocab[:10]}\")\n",
        "print(f\"least common words in the vocabulary is \\n {rct_20k_text_vocab[-10:]}\")\n",
        "\n",
        "# print text vectorization config\n",
        "t_config = text_vectorization.get_config()\n",
        "print(t_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b911e8",
      "metadata": {
        "id": "c0b911e8"
      },
      "source": [
        "### Token Embedding (266)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "6e22319f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e22319f",
        "outputId": "0f0fe60a-ae2f-4494-8190-101190c8e14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before embedding \n",
            " The image quality and radiation dose of two groups were compared .\n",
            "vectorized sentence \n",
            " [[   2 1277  141    3  918  131    4   51   24    9   34    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "embedded sentence \n",
            " [[[-0.03166427 -0.04835395 -0.01674293 ... -0.0006644   0.03185214\n",
            "    0.03218943]\n",
            "  [ 0.00624212 -0.0107929  -0.03451354 ... -0.00299595  0.00321888\n",
            "   -0.01675998]\n",
            "  [ 0.02171237 -0.03875266  0.02743942 ... -0.00554638 -0.00289248\n",
            "   -0.0201643 ]\n",
            "  ...\n",
            "  [-0.04244796 -0.04561872  0.03256536 ... -0.01859445 -0.01254741\n",
            "    0.01689316]\n",
            "  [-0.04244796 -0.04561872  0.03256536 ... -0.01859445 -0.01254741\n",
            "    0.01689316]\n",
            "  [-0.04244796 -0.04561872  0.03256536 ... -0.01859445 -0.01254741\n",
            "    0.01689316]]]\n",
            "embedded sentence shape \n",
            " (1, 55, 128)\n"
          ]
        }
      ],
      "source": [
        "# add a embedding layer\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                 output_dim=128,\n",
        "                  mask_zero=True,\n",
        "                  name='token_embedding')\n",
        "# token embedding\n",
        "print(f\"Sentence before embedding \\n {sample_sentence}\")\n",
        "vectorized_sentence = text_vectorization([sample_sentence])\n",
        "print(f\"vectorized sentence \\n {vectorized_sentence}\")\n",
        "embed_sentence = embedding_layer(vectorized_sentence)\n",
        "print(f\"embedded sentence \\n {embed_sentence}\")\n",
        "print(f\"embedded sentence shape \\n {embed_sentence.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d954fa5",
      "metadata": {
        "id": "1d954fa5"
      },
      "source": [
        "## Create Dataset using tf.data.Dataset (267)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "86b0e2b0",
      "metadata": {
        "id": "86b0e2b0"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_label_one_hot))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences,val_label_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences,test_label_one_hot))\n",
        "\n",
        "# for fast performance \n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset   = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset  = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "c1280fc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1280fc6",
        "outputId": "5b495930-e30c-423f-882c-7034585cf069"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40beeb95",
      "metadata": {
        "id": "40beeb95"
      },
      "source": [
        "## Build Conv1D model (268)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "4bde1b93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bde1b93",
        "outputId": "050adf56-ea09-4b7b-f093-aa72ef44c9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1)]               0         \n",
            "                                                                 \n",
            " vectorization_layer (TextVe  (None, 55)               0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " token_embedding_layer (Embe  (None, 55, 128)          8299648   \n",
            " dding)                                                          \n",
            "                                                                 \n",
            " conv1d_Layer (Conv1D)       (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling (Glo  (None, 64)               0         \n",
            " balAveragePooling1D)                                            \n",
            "                                                                 \n",
            " fully_connected (Dense)     (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Input, TextVectorization, Embedding,Dense\n",
        "\n",
        "# input layer\n",
        "inputs = Input(shape=(1,),dtype=tf.string,name=\"input\")\n",
        "# text vectorization layer\n",
        "max_tokens = 68000\n",
        "lengths = [len(sen.split()) for sen in train_sentences]\n",
        "output_sequence_length = int(np.percentile(lengths,95))\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
        "                      output_sequence_length=output_sequence_length,\n",
        "                                   name=\"vectorization_layer\")\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "vectors = text_vectorizer(inputs)\n",
        "# embedding layer\n",
        "embedding = Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                     output_dim=128,\n",
        "                     mask_zero=True,\n",
        "                      name=\"token_embedding_layer\")\n",
        "token_embedding = embedding(vectors)\n",
        "# conv1d layer\n",
        "x = Conv1D(filters=64,\n",
        "          kernel_size=5,\n",
        "          padding=\"same\",\n",
        "          activation=\"relu\",\n",
        "          name=\"conv1d_Layer\")(token_embedding)\n",
        "# average pooling\n",
        "x = GlobalAveragePooling1D(name=\"global_average_pooling\")(x)\n",
        "# output layer\n",
        "outputs = Dense(5,activation=\"softmax\", name=\"fully_connected\")(x)\n",
        "# finally the model\n",
        "model_1 = Model(inputs,outputs)\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=['accuracy'])\n",
        "# summary\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "258d5d14",
      "metadata": {
        "id": "258d5d14"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def fit_the_model(model):\n",
        "    \n",
        "    # fit the model\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_dataset,\n",
        "                             steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              epochs=3,\n",
        "                             validation_data=val_dataset,\n",
        "                             validation_steps=int(0.1*len(val_dataset)))\n",
        "    time_taken = time.time() - start_time\n",
        "    print(f\"time taken to fit {time_taken}\")\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "bdeb7258",
      "metadata": {
        "id": "bdeb7258"
      },
      "outputs": [],
      "source": [
        "# let's try with cpu\n",
        "#with tf.device(\"/cpu:0\"):\n",
        "#    fit_the_model(model_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "af51073f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af51073f",
        "outputId": "f8e1009b-58e0-47cb-e647-13605d1db90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 37s 64ms/step - loss: 0.9167 - accuracy: 0.6397 - val_loss: 0.6846 - val_accuracy: 0.7374\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 8s 15ms/step - loss: 0.6576 - accuracy: 0.7567 - val_loss: 0.6292 - val_accuracy: 0.7729\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 5s 9ms/step - loss: 0.6169 - accuracy: 0.7751 - val_loss: 0.5965 - val_accuracy: 0.7839\n",
            "time taken to fit 82.58137202262878\n"
          ]
        }
      ],
      "source": [
        "# with gpu\n",
        "with tf.device(\"/gpu:0\"):\n",
        "    fit_the_model(model_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "6467abc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6467abc4",
        "outputId": "d324092e-7856-4677-89aa-e3decec22aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 3s 3ms/step - loss: 0.5988 - accuracy: 0.7865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5988160967826843, 0.786541759967804]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# evalue the model\n",
        "model_1.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "a8f0d4c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8f0d4c4",
        "outputId": "b5740d7d-f7e9-47d4-bcda-e890f763b8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.25897270e-01, 1.87222391e-01, 8.77792016e-02, 2.49361023e-01,\n",
              "         4.97401319e-02],\n",
              "        [4.29359913e-01, 3.02828640e-01, 1.44873485e-02, 2.42373854e-01,\n",
              "         1.09503735e-02],\n",
              "        [1.47737727e-01, 6.19906746e-03, 2.26519560e-03, 8.43740761e-01,\n",
              "         5.71989076e-05],\n",
              "        ...,\n",
              "        [3.83057068e-06, 4.66149533e-04, 6.16704056e-04, 1.71395902e-06,\n",
              "         9.98911619e-01],\n",
              "        [5.31462580e-02, 4.76215214e-01, 9.06681493e-02, 5.96981794e-02,\n",
              "         3.20272177e-01],\n",
              "        [1.48565754e-01, 6.77031994e-01, 4.34985347e-02, 5.59228882e-02,\n",
              "         7.49808028e-02]], dtype=float32),\n",
              " (30212, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model_1_pred_probs = model_1.predict(val_dataset)\n",
        "model_1_pred_probs,model_1_pred_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "812bd5af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "812bd5af",
        "outputId": "cc0e96b6-5607-40b8-f9e8-6d18b2fce2ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "model_1_preds = tf.argmax(model_1_pred_probs,axis=1)\n",
        "model_1_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "96d569f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96d569f5",
        "outputId": "fbf5c15a-ef6c-4ccb-eb74-f0680d93d06b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy_score': 0.7218323844829869,\n",
              "  'precision_score': 0.7186466952323352,\n",
              "  'recall_score': 0.7218323844829869,\n",
              "  'f1_score': 0.6989250353450294},\n",
              " {'accuracy_score': 0.7865417714815305,\n",
              "  'precision_score': 0.783231157574636,\n",
              "  'recall_score': 0.7865417714815305,\n",
              "  'f1_score': 0.7839046443651448})"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "model_1_results = find_scores(val_label_encoded,model_1_preds)\n",
        "model_0_results,model_1_results,"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "459a3f58",
      "metadata": {
        "id": "459a3f58"
      },
      "source": [
        "## Model 2 Architecture - Tensorflow Hub Pretrained Feature Extractor (269 - 270)\n",
        "![Model 2 Architecture](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/model_2_architecture.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "e13d93ab",
      "metadata": {
        "id": "e13d93ab"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    use = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
        "    universal_sentence_encoder = hub.KerasLayer(use,\n",
        "                              trainable=False,\n",
        "                              name='universal_encoder_layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "a2c17726",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2c17726",
        "outputId": "fa48c945-dbe2-42f1-ef1a-c22a47205eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random sentence to encode with hub encoder \n",
            " In this study , the percentage of `` dippers '' was considerably higher than the one described in previous studies on the role of perfusion pressure in glaucoma .\n",
            "shape of encoded sentence (1, 512)\n",
            "encoded sentence \n",
            " [[ 0.05318759  0.06694195 -0.02285054 -0.06648646 -0.00172862 -0.03838197\n",
            "   0.05471945  0.02077011  0.07190014  0.0492602   0.06337104  0.05554748\n",
            "   0.07881077 -0.03388673  0.01749495 -0.01766438 -0.07889563  0.07268333\n",
            "   0.05590377 -0.0546833  -0.06824004 -0.04443037 -0.05573618 -0.03782691\n",
            "   0.04648034 -0.02922353  0.02489529 -0.03093434 -0.0196235   0.02058689\n",
            "   0.0514342   0.08157799  0.04686048  0.05630185 -0.04615793 -0.05004493\n",
            "  -0.05951475  0.03040069 -0.05621374  0.03439063  0.01125715  0.06705008\n",
            "  -0.0517599  -0.05978227 -0.00304865 -0.05005432 -0.05335239  0.04448131\n",
            "   0.07222652 -0.00139782 -0.03142246  0.05329077  0.04937031 -0.0085967\n",
            "  -0.07300458 -0.05582274 -0.06392371  0.00025338  0.02529376  0.02467687\n",
            "   0.03867016  0.02682601  0.07479726  0.05537133 -0.02092089 -0.01821097\n",
            "   0.04220151  0.01808328  0.00583711 -0.00085979  0.00804989  0.07412348\n",
            "  -0.04978912  0.05756349 -0.0222225   0.01829336  0.03028951 -0.02999905\n",
            "   0.00066365  0.036791    0.02956044 -0.00172916 -0.04415236  0.08338011\n",
            "  -0.06127031  0.02041247 -0.00852013  0.0344348   0.0053535  -0.05968761\n",
            "   0.00949012  0.02553898  0.01753378 -0.00034966 -0.06884965  0.06936788\n",
            "  -0.04292598 -0.03211023  0.00673239  0.00638924 -0.03338802  0.05331695\n",
            "   0.02212222  0.01772643  0.06826241 -0.072834    0.02558957 -0.01198089\n",
            "   0.0465542   0.00185266 -0.01681455  0.05706834  0.04469968  0.03006368\n",
            "   0.01517109  0.05377146  0.05064533  0.05183332  0.03941575  0.05386422\n",
            "  -0.01094282 -0.00270729  0.06233745  0.04091289 -0.04872388  0.02277175\n",
            "  -0.08355157 -0.02023907 -0.02557862  0.0546474  -0.05448264  0.0888183\n",
            "   0.04292253  0.04551503 -0.04571876 -0.06836309  0.00614624  0.04757877\n",
            "   0.00802928 -0.0677008  -0.01819302  0.00580904 -0.04520182 -0.06369626\n",
            "   0.07525294  0.03075144 -0.03879977  0.00074491  0.01016354  0.00962772\n",
            "  -0.04570557  0.0655761  -0.00466919  0.02683913 -0.00171158  0.03784912\n",
            "  -0.00127035  0.05285222  0.06480858 -0.0270728   0.00712962 -0.06613413\n",
            "  -0.04208988 -0.06436361 -0.06366584 -0.05862513  0.00651205  0.00609429\n",
            "  -0.03301546 -0.01126307  0.05475051  0.0183229  -0.03301358  0.06811465\n",
            "   0.02335097 -0.01072374  0.00341749 -0.05285249 -0.00479517  0.06401221\n",
            "   0.0060358  -0.08002719  0.03068353 -0.02307104  0.06453837 -0.03816037\n",
            "   0.08520981  0.00093576  0.0572902   0.05422057  0.00421125  0.02557321\n",
            "  -0.0497372   0.08079374 -0.05356217  0.03354885 -0.06009857 -0.05453926\n",
            "  -0.05174324 -0.06617896  0.0751125  -0.02502799 -0.00500535  0.04261258\n",
            "  -0.07744823  0.01739718 -0.07912594 -0.00401712  0.04425631  0.047755\n",
            "   0.03238019 -0.00573485 -0.00598213  0.05814904  0.00947707  0.04803868\n",
            "   0.02600932  0.01239994 -0.06050635  0.01719971 -0.04282164  0.04488344\n",
            "  -0.0434289   0.03174138  0.04123664  0.06296257 -0.03082557 -0.05549667\n",
            "  -0.03868835  0.04595989 -0.04651362  0.01418686 -0.0017741  -0.04862961\n",
            "  -0.04577403 -0.00429094  0.07306613  0.04356247 -0.03259478  0.06580807\n",
            "  -0.01693393 -0.00444691 -0.0163216  -0.02548216  0.04810459 -0.07874998\n",
            "   0.02570562  0.01253117 -0.04695769 -0.08567373  0.07770315 -0.06681765\n",
            "  -0.03228901 -0.05680922  0.03979665  0.03973715 -0.05640814  0.06812858\n",
            "  -0.0485476   0.03025046 -0.03451179 -0.05868382 -0.06285772  0.04833966\n",
            "   0.00427429  0.04093394  0.03114074  0.0109587  -0.03099799 -0.01221244\n",
            "   0.06100383  0.02669771  0.05849173  0.02339928  0.00706025  0.0057053\n",
            "  -0.06442195 -0.07185584 -0.02592374 -0.0416981  -0.05183781 -0.00789152\n",
            "   0.03241743 -0.01788587  0.0568934   0.01971369 -0.06123766  0.02539544\n",
            "  -0.03585814 -0.01291041  0.01627296 -0.03602099  0.04068892 -0.0028057\n",
            "  -0.07022563 -0.0595501  -0.06390938  0.04523893  0.06562868  0.0353576\n",
            "   0.00822946 -0.03756467  0.01938112 -0.0653041  -0.05924901  0.04868997\n",
            "   0.03115227  0.03061631 -0.02217369  0.03988014 -0.03321484  0.01205178\n",
            "   0.03550212  0.00711971 -0.0227264  -0.01576852  0.04776847 -0.02102184\n",
            "  -0.0165791  -0.0681578  -0.04610953 -0.01790832  0.04305973  0.08275238\n",
            "  -0.02665442 -0.03141167  0.05557719 -0.07677884 -0.0880283   0.06342356\n",
            "  -0.07382768  0.05874575  0.06016849  0.00906276 -0.02832865  0.03268491\n",
            "   0.00267619 -0.02545256  0.04814518 -0.02881084  0.01126474  0.03749297\n",
            "   0.05890371  0.06286555 -0.01565338 -0.08508682  0.01289492  0.02450746\n",
            "  -0.00833306 -0.0615122   0.01979896 -0.05765461  0.04125586 -0.07628375\n",
            "   0.06759197 -0.02145507  0.06151558  0.03300076  0.05342256 -0.06179938\n",
            "   0.06724615  0.05285154  0.03698624 -0.03601221 -0.02909922 -0.03363741\n",
            "  -0.03624895  0.0486946  -0.01536783  0.00301329 -0.05041803 -0.00362785\n",
            "  -0.00104445 -0.00066979 -0.0414176  -0.00615478 -0.00573311 -0.01511829\n",
            "   0.05184901 -0.05981795 -0.01761124  0.00185699  0.05124544  0.07378629\n",
            "  -0.02059316  0.04516584  0.05191474 -0.00161677  0.07198832 -0.03245239\n",
            "   0.06658223  0.04190683 -0.05795917 -0.02987163  0.05650666 -0.0478598\n",
            "   0.0348311   0.02184777  0.01784046 -0.03885243 -0.00883633  0.03074149\n",
            "  -0.03923262  0.04861869 -0.04967145  0.02815986 -0.07107688  0.04596582\n",
            "  -0.02621352  0.01374649  0.01350633 -0.00978444  0.0155754  -0.0306995\n",
            "   0.04829977 -0.0451542   0.04782953  0.0302611  -0.0471819  -0.02538435\n",
            "   0.05192938 -0.02612753  0.03010846 -0.03494352  0.0504674   0.00514296\n",
            "   0.03098056  0.04458528 -0.02954398 -0.04258869 -0.06311911  0.01008522\n",
            "  -0.01845426 -0.05033359 -0.00080979  0.04288403 -0.04466503 -0.01851218\n",
            "   0.05257117  0.04897757 -0.0129216   0.04570289  0.05486219  0.03872987\n",
            "   0.03328687 -0.05973128  0.0205232  -0.02124158  0.0095464   0.02424164\n",
            "   0.0414929  -0.08018213 -0.01870257 -0.00550543 -0.03615706 -0.02625968\n",
            "   0.07054769  0.04373798 -0.01232594  0.0481231   0.04231096 -0.04711372\n",
            "   0.06898063  0.05823705  0.01251241 -0.03590263 -0.01313836 -0.02591912\n",
            "   0.00763402 -0.08560003 -0.07666927 -0.04027424 -0.05291422 -0.06725178\n",
            "  -0.03195523  0.02043009 -0.06975657 -0.01100407  0.06016418  0.0004066\n",
            "  -0.02300871 -0.01709075 -0.05857154  0.04293984  0.03681142  0.01198154\n",
            "  -0.06760978  0.00728507  0.03635127 -0.06583224 -0.03613578 -0.01505913\n",
            "   0.00137729 -0.03517202 -0.0096627  -0.05595578 -0.00341452 -0.02960435\n",
            "   0.07110251  0.04996216  0.02106606 -0.02032145  0.05193511 -0.05804079\n",
            "  -0.05839733 -0.08927564  0.01531079 -0.05866734  0.01829861 -0.02043092\n",
            "   0.05012684 -0.01899114]]\n"
          ]
        }
      ],
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"random sentence to encode with hub encoder \\n {random_sentence}\")\n",
        "random_sentence_encoded = universal_sentence_encoder([random_sentence])\n",
        "print(f\"shape of encoded sentence {random_sentence_encoded.shape}\")\n",
        "print(f\"encoded sentence \\n {random_sentence_encoded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "cc10e4bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc10e4bd",
        "outputId": "36b12151-80d0-4690-fd4e-b665711f3d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_use_feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_encoder_layer (Ke  (None, 512)              256797824 \n",
            " rasLayer)                                                       \n",
            "                                                                 \n",
            " fully_connected_layer (Dens  (None, 128)              65664     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# create model 2\n",
        "inputs = Input(shape=[],dtype=tf.string,name='input_layer')\n",
        "pretrained_embedding = universal_sentence_encoder(inputs)\n",
        "dense = Dense(128,activation='relu',name='fully_connected_layer')(pretrained_embedding)\n",
        "outputs = Dense(5,activation='softmax',name='output_layer')(dense)\n",
        "model_2 = Model(inputs=inputs,\n",
        "               outputs=outputs,\n",
        "               name='model_2_use_feature_extractor')\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=['accuracy'])\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "c1c649ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1c649ed",
        "outputId": "6dff59c8-9a07-4f96-a0b3-3eaa49f5544c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 16s 23ms/step - loss: 0.9180 - accuracy: 0.6451 - val_loss: 0.7970 - val_accuracy: 0.6928\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 11s 19ms/step - loss: 0.7691 - accuracy: 0.7016 - val_loss: 0.7554 - val_accuracy: 0.7045\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 11s 19ms/step - loss: 0.7509 - accuracy: 0.7132 - val_loss: 0.7402 - val_accuracy: 0.7081\n",
            "time taken to fit 43.26831245422363\n"
          ]
        }
      ],
      "source": [
        "model_2_history = fit_the_model(model_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "4eaa169b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eaa169b",
        "outputId": "5a8bf13c-013a-4d04-9254-1d89efe1341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 15s 16ms/step - loss: 0.7408 - accuracy: 0.7133\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7408479452133179, 0.7133258581161499]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "model_2.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "5f5ea285",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f5ea285",
        "outputId": "44f21f20-1113-4275-8bfa-ae8c44a52f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 14s 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3022779e-01, 3.6558852e-01, 2.0890015e-03, 1.9409186e-01,\n",
              "        8.0028502e-03],\n",
              "       [3.8171786e-01, 4.8755890e-01, 2.7875034e-03, 1.2525596e-01,\n",
              "        2.6797422e-03],\n",
              "       [2.3645023e-01, 1.4428087e-01, 1.7522851e-02, 5.6684375e-01,\n",
              "        3.4902353e-02],\n",
              "       ...,\n",
              "       [1.4717447e-03, 4.8406082e-03, 4.3081600e-02, 7.2230340e-04,\n",
              "        9.4988376e-01],\n",
              "       [3.4473655e-03, 4.5321833e-02, 1.9738352e-01, 1.6234010e-03,\n",
              "        7.5222385e-01],\n",
              "       [1.5881562e-01, 2.6100177e-01, 5.1572001e-01, 6.7319036e-03,\n",
              "        5.7730727e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "model_2_pred_probs = model_2.predict(val_dataset)\n",
        "model_2_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "549d25f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "549d25f5",
        "outputId": "2164f808-22df-416e-b0c2-18364c58db5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "model_2_pred = tf.argmax(model_2_pred_probs,axis=1)\n",
        "model_2_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "827c8e23",
      "metadata": {
        "id": "827c8e23"
      },
      "outputs": [],
      "source": [
        "model_2_results = find_scores(val_label_encoded,model_2_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "801a37bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801a37bb",
        "outputId": "b0a2c232-c367-4989-ea19-b8fa28db7b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy_score': 0.7133258307957103,\n",
              "  'precision_score': 0.7137064548866401,\n",
              "  'recall_score': 0.7133258307957103,\n",
              "  'f1_score': 0.7102510350389353},\n",
              " {'accuracy_score': 0.7865417714815305,\n",
              "  'precision_score': 0.783231157574636,\n",
              "  'recall_score': 0.7865417714815305,\n",
              "  'f1_score': 0.7839046443651448},\n",
              " {'accuracy_score': 0.7218323844829869,\n",
              "  'precision_score': 0.7186466952323352,\n",
              "  'recall_score': 0.7218323844829869,\n",
              "  'f1_score': 0.6989250353450294})"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "model_2_results,model_1_results,model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53053f8",
      "metadata": {
        "id": "b53053f8"
      },
      "source": [
        "## Model-3 : Conv1D with character embedding\n",
        "\n",
        "![Model 3 Architecture](https://raw.githubusercontent.com/rkumar-bengaluru/data-science/main/20-Tensorflow/07-Skimlit/resources/model_3_architecture.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225b796f",
      "metadata": {
        "id": "225b796f"
      },
      "source": [
        "### Character Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "96334d88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "96334d88",
        "outputId": "f9a6dc79-9da0-424a-c32c-f67a12b0b6cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "import random\n",
        "from tensorflow.data import Dataset\n",
        "# prepare data\n",
        "def split_chars(sentence):\n",
        "    return ' '.join(list(sentence))\n",
        "\n",
        "\n",
        "training_char_sentences = [split_chars(sentence.lower()) for sentence in train_sentences]\n",
        "val_char_sentences      = [split_chars(sentence.lower()) for sentence in val_sentences]\n",
        "test_char_sentences     = [split_chars(sentence.lower()) for sentence in test_sentences]\n",
        "training_char_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences[0]), len(training_char_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKm_wY2uI-p4",
        "outputId": "db626559-764e-46d3-b1bf-76a2fd341f03"
      },
      "id": "KKm_wY2uI-p4",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(281, 561)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf0LOrSjiTsq",
        "outputId": "23ff8044-2bb4-4445-9444-c470531aac4d"
      },
      "id": "hf0LOrSjiTsq",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 27 08:07:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    32W /  70W |   1665MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "c2eb3e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2eb3e97",
        "outputId": "7976e7aa-3750-41fc-f94a-199b79ff391a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of tokens to consider 579 \n",
            "vocabulary \n",
            " ['', '[UNK]', 'e', 't', 'i', 'a', 'n', 'o', 'r', 's', 'd', 'c', 'l', 'h', 'p', 'm', 'u', 'f', 'g', 'y', 'w', 'v', 'b', 'k', 'x', 'z', 'q', 'j']\n",
            "vocabulary length \n",
            " 28\n",
            "encoded random sample \n",
            " [[ 3 13  2 14  4 21  7  3  5 12 12  2 21  5  6  3  3  8  4  5 12 20  5  9\n",
            "  10  2  9  4 18  6  2 10  4  6 11  7 12 12  5 22  7  8  5  3  4  7  6 20\n",
            "   4  3 13  3 13  2 16  9 17  7  7 10  5  6 10 10  8 16 18  5 10 15  4  6\n",
            "   4  9  3  8  5  3  4  7  6  3  7 10  2 15  7  6  9  3  8  5  3  2  9  5\n",
            "  17  2  3 19  5  6 10  2 17 17  4 11  5 11 19  4  6  5 12  5  8 18  2 14\n",
            "   7 14 16 12  5  3  4  7  6  5  6 10  3  7  7 22  3  5  4  6 16  9 17  7\n",
            "   7 10  5  6 10 10  8 16 18  5 10 15  4  6  4  9  3  8  5  3  4  7  6  5\n",
            "  14 14  8  7 21  5 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]]\n",
            "shape of encoded sample char sentence \n",
            " (1, 579)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.data import Dataset\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "lengths_of_sentences = [len(sentence) for sentence in training_char_sentences]\n",
        "# find no of tokens to take to cover 95 % of the data\n",
        "max_length = int(np.percentile(lengths_of_sentences,95)) # sequence length to pad the outputs to\n",
        "print(f\"number of tokens to consider {max_length} \")\n",
        "# find vocab length\n",
        "all_printable = string.ascii_lowercase + string.digits + string.punctuation\n",
        "max_features = len(all_printable); # no of characters in the vocabulary\n",
        "char_vectorizer = TextVectorization(max_tokens=max_features,\n",
        "                                   output_sequence_length=max_length,\n",
        "                                   name='character_vectorization')\n",
        "\n",
        "#test_char_dataset  = Dataset.from_tensor_slices((test_char_sentences,test_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "char_vectorizer.adapt(training_char_sentences)\n",
        "vocab = char_vectorizer.get_vocabulary()\n",
        "sample_char_sentence = random.choice(training_char_sentences)\n",
        "print(f\"vocabulary \\n {vocab}\")\n",
        "print(f\"vocabulary length \\n {len(vocab)}\")\n",
        "sample_sentence_encoded = char_vectorizer([sample_char_sentence])\n",
        "print(f\"encoded random sample \\n {sample_sentence_encoded}\")\n",
        "print(f\"shape of encoded sample char sentence \\n {sample_sentence_encoded.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "b0b39041",
      "metadata": {
        "id": "b0b39041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc1b1c2-8e30-4e2a-df2d-1a1d2052df03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 579, 25), dtype=float32, numpy=\n",
              "array([[[ 4.6243098e-02, -3.0916452e-02, -4.1553438e-02, ...,\n",
              "         -3.9566327e-02, -2.2794617e-02,  4.7771309e-02],\n",
              "        [-4.4480313e-02,  5.3178519e-05, -1.9883906e-02, ...,\n",
              "          2.4383549e-02,  4.4254065e-03,  1.5555289e-02],\n",
              "        [-1.2828819e-03,  1.2885045e-02, -3.4994591e-02, ...,\n",
              "         -4.6617962e-02, -4.9610447e-02,  6.7821369e-03],\n",
              "        ...,\n",
              "        [ 1.3826165e-02,  8.8455901e-03, -3.9451979e-02, ...,\n",
              "         -2.7777329e-03, -1.8999970e-02, -4.7133625e-02],\n",
              "        [ 1.3826165e-02,  8.8455901e-03, -3.9451979e-02, ...,\n",
              "         -2.7777329e-03, -1.8999970e-02, -4.7133625e-02],\n",
              "        [ 1.3826165e-02,  8.8455901e-03, -3.9451979e-02, ...,\n",
              "         -2.7777329e-03, -1.8999970e-02, -4.7133625e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# embedding layer\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "char_embedding = Embedding(input_dim=len(vocab),\n",
        "                          output_dim=25,\n",
        "                          mask_zero=True,\n",
        "                          name='char_embedding_layer')\n",
        "char_embedding_sample = char_embedding(sample_sentence_encoded)\n",
        "char_embedding_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd96d1c",
      "metadata": {
        "id": "1fd96d1c"
      },
      "source": [
        "### Create Full Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "f3e6425b",
      "metadata": {
        "id": "f3e6425b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input,Dense, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "inputs = Input(shape=(1,),dtype=tf.string,name='input_layer')\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embedding(char_vectors)\n",
        "x = Conv1D(filters=64,\n",
        "          kernel_size=5,\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv_1d_layer')(char_embeddings)\n",
        "x = GlobalMaxPooling1D(name='GlobalAveragePooling1D')(x)\n",
        "outputs = Dense(units=5,activation='softmax',name='full_connected')(x)\n",
        "model_3 = Model(inputs,outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "8614ad44",
      "metadata": {
        "id": "8614ad44"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model_3.compile(loss='categorical_crossentropy',\n",
        "               optimizer=Adam(),\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbd6c19c",
      "metadata": {
        "id": "fbd6c19c"
      },
      "source": [
        "### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "1a5eabe4",
      "metadata": {
        "id": "1a5eabe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d604f7-ab4d-4323-9d03-163868f41495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 1)]               0         \n",
            "                                                                 \n",
            " character_vectorization (Te  (None, 579)              0         \n",
            " xtVectorization)                                                \n",
            "                                                                 \n",
            " char_embedding_layer (Embed  (None, 579, 25)          700       \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " conv_1d_layer (Conv1D)      (None, 579, 64)           8064      \n",
            "                                                                 \n",
            " GlobalAveragePooling1D (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " full_connected (Dense)      (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,089\n",
            "Trainable params: 9,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "507958c7",
      "metadata": {
        "id": "507958c7"
      },
      "source": [
        "### Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "886041e2",
      "metadata": {
        "id": "886041e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84f466c-3940-401b-ad9b-fb82c8115dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "train_char_dataset = Dataset.from_tensor_slices((training_char_sentences,train_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset   = Dataset.from_tensor_slices((val_char_sentences,val_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_char_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data = val_char_dataset,\n",
        "                              validation_steps=int(0.1* len(val_char_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeZqWo04L0GJ",
        "outputId": "a5f874af-5cb3-4ee3-e5c0-b68cf0c94d53"
      },
      "id": "XeZqWo04L0GJ",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 6s 8ms/step - loss: 1.2774 - accuracy: 0.4911 - val_loss: 1.0390 - val_accuracy: 0.5934\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 4s 6ms/step - loss: 0.9961 - accuracy: 0.6041 - val_loss: 0.9254 - val_accuracy: 0.6423\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 4s 6ms/step - loss: 0.9229 - accuracy: 0.6406 - val_loss: 0.8608 - val_accuracy: 0.6689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08dea307",
      "metadata": {
        "id": "08dea307"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "2fdea782",
      "metadata": {
        "id": "2fdea782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d70add-8fda-45f2-836b-2fe61bc29017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.8828 - accuracy: 0.6599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8827860951423645, 0.659903347492218]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "model_3.evaluate(val_char_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR8YlESUMUPa",
        "outputId": "ef698c03-ce94-490a-a0ea-d83c1dca59f8"
      },
      "id": "qR8YlESUMUPa",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 3s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20906991, 0.2852331 , 0.1061962 , 0.36528558, 0.03421525],\n",
              "       [0.14336343, 0.62452275, 0.01603543, 0.132709  , 0.08336942],\n",
              "       [0.1836357 , 0.24959509, 0.13346061, 0.37408265, 0.05922596],\n",
              "       ...,\n",
              "       [0.04084775, 0.06709307, 0.17775017, 0.07735576, 0.63695323],\n",
              "       [0.03433852, 0.08231415, 0.2551456 , 0.0554155 , 0.5727862 ],\n",
              "       [0.36113063, 0.36512938, 0.16557115, 0.07621456, 0.03195424]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds = tf.argmax(model_3_pred_probs,axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZvjJ1bdMeEh",
        "outputId": "a76aab34-8ed2-4b5f-8cc1-e29d3fcc2ac0"
      },
      "id": "kZvjJ1bdMeEh",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([3, 1, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = find_scores(val_label_encoded,model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wpD5udUMmHj",
        "outputId": "a3309329-e6a7-4ac3-b530-7b1e761405a5"
      },
      "id": "4wpD5udUMmHj",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_score': 0.6599033496623858,\n",
              " 'precision_score': 0.6514968877552941,\n",
              " 'recall_score': 0.6599033496623858,\n",
              " 'f1_score': 0.6477108860424121}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pr-qyPsHMyf_"
      },
      "id": "pr-qyPsHMyf_",
      "execution_count": 114,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}