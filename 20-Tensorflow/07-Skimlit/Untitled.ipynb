{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57714cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt', 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# root data directory\n",
    "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
    "# list of file names\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "134e27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train lines is 210040\n",
      "size of validation lines is 35212\n",
      "size of test lines is 35135\n",
      "size of train data is 180040\n",
      "size of validation data is 30212\n",
      "size of test data is 30135\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_lines(file_name):\n",
    "    \"\"\"\n",
    "    Reads the file_name and returns the content of the file as list\n",
    "    \"\"\"\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "validation_lines = get_lines(filenames[0])\n",
    "test_lines = get_lines(filenames[1])\n",
    "train_lines = get_lines(filenames[2])\n",
    "\n",
    "print(f\"size of train lines is {len(train_lines)}\")\n",
    "print(f\"size of validation lines is {len(validation_lines)}\")\n",
    "print(f\"size of test lines is {len(test_lines)}\")\n",
    "\n",
    "def create_data_set(lines):\n",
    "    data = []\n",
    "    items = []\n",
    "    index = 0\n",
    "    for line in lines:\n",
    "        \n",
    "        if line.startswith('\\n'):\n",
    "            for item in items:\n",
    "                item['total_lines'] = index -1\n",
    "                data.append(item)\n",
    "            index = 0\n",
    "            items = []\n",
    "        else:\n",
    "            tokens = line.split('\\t')\n",
    "        \n",
    "            if len(tokens) > 1:\n",
    "                item = {'line_number':index,'target': tokens[0],'text':tokens[1].strip() ,'total_lines' :index}\n",
    "                items.append(item)\n",
    "                index = index + 1\n",
    "    return data\n",
    "\n",
    "train_data = create_data_set(train_lines)\n",
    "validation_data = create_data_set(validation_lines)\n",
    "test_data = create_data_set(test_lines)\n",
    "\n",
    "print(f\"size of train data is {len(train_data)}\")\n",
    "print(f\"size of validation data is {len(validation_data)}\")\n",
    "print(f\"size of test data is {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b6824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df   = pd.DataFrame(validation_data)\n",
    "test_df  = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183e3dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences length 180040\n",
      "val sentences length 30212\n",
      "test sentences length 30135\n"
     ]
    }
   ],
   "source": [
    "# convert to list\n",
    "train_sentences = train_df['text'].tolist()\n",
    "val_sentences   = val_df['text'].tolist()\n",
    "test_sentences  = test_df['text'].tolist()\n",
    "print(f\"train sentences length {len(train_sentences)}\")\n",
    "print(f\"val sentences length {len(val_sentences)}\")\n",
    "print(f\"test sentences length {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0339d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding\n",
      "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float64)\n",
      "label encoding...\n",
      "3 0 0\n",
      "classnames\n",
      "class name =  ['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS'] length of classes = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rupak\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Rupak\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "train_label_one_hot = tf.constant(onehot.fit_transform(train_df['target'].to_numpy().reshape(-1,1)))\n",
    "val_label_one_hot    = tf.constant(onehot.transform(val_df['target'].to_numpy().reshape(-1,1)))\n",
    "test_label_one_hot   = tf.constant(onehot.transform(test_df['target'].to_numpy().reshape(-1,1)))\n",
    "print('one hot encoding')\n",
    "print(train_label_one_hot[0],val_label_one_hot[0],test_label_one_hot[0])\n",
    "\n",
    "# label encoder\n",
    "labelencode = LabelEncoder()\n",
    "train_label_encoded = labelencode.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
    "val_label_encoded = labelencode.transform(val_df['target'].to_numpy().reshape(-1,1))\n",
    "test_label_encoded = labelencode.transform(test_df['target'].to_numpy().reshape(-1,1))\n",
    "print('label encoding...')\n",
    "print(train_label_encoded[0],val_label_encoded[0],test_label_encoded[0])\n",
    "\n",
    "print('classnames')\n",
    "classnames = labelencode.classes_\n",
    "print('class name = ', classnames, 'length of classes =', len(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786ce1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_label_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences,val_label_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences,test_label_one_hot))\n",
    "\n",
    "# for fast performance \n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset  = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a579fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('resources/model/pubmed_model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc0fa137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step - loss: 0.6003 - accuracy: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6003004908561707, 0.7849199175834656]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d8b023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c2a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
